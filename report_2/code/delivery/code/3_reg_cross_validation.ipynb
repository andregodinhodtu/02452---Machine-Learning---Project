{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4599cd41",
   "metadata": {},
   "source": [
    "python 3.13.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242ed63",
   "metadata": {},
   "source": [
    "# reg_part_B_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ba25",
   "metadata": {},
   "source": [
    "# Data import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13ac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data_file=\"heart_failure_clinical_records_dataset\"\n",
    "\n",
    "data = pd.read_csv(f\"../../raw_data/{name_data_file}.csv\", na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac829f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0    75.0        0                       582         0                 20   \n",
       "1    55.0        0                      7861         0                 38   \n",
       "2    65.0        0                       146         0                 20   \n",
       "3    50.0        1                       111         0                 20   \n",
       "4    65.0        1                       160         1                 20   \n",
       "..    ...      ...                       ...       ...                ...   \n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      1  265000.00               1.9           130    1   \n",
       "1                      0  263358.03               1.1           136    1   \n",
       "2                      0  162000.00               1.3           129    1   \n",
       "3                      0  210000.00               1.9           137    1   \n",
       "4                      0  327000.00               2.7           116    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "294                    1  155000.00               1.1           143    1   \n",
       "295                    0  270000.00               1.2           139    0   \n",
       "296                    0  742000.00               0.8           138    0   \n",
       "297                    0  140000.00               1.4           140    1   \n",
       "298                    0  395000.00               1.6           136    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "0          0     4            1  \n",
       "1          0     6            1  \n",
       "2          1     7            1  \n",
       "3          0     7            1  \n",
       "4          0     8            1  \n",
       "..       ...   ...          ...  \n",
       "294        1   270            0  \n",
       "295        0   271            0  \n",
       "296        0   278            0  \n",
       "297        1   280            0  \n",
       "298        1   285            0  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598f101",
   "metadata": {},
   "source": [
    "# Cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c41e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['time', \"DEATH_EVENT\"])\n",
    "X[\"creatinine_phosphokinase\"] = np.log1p(X[\"creatinine_phosphokinase\"])\n",
    "y = data['time']   # pandas Series\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "# X.shape, y.shape print shapes of X and y to undestand their dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3341fec",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86e127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data based on training set\n",
    "\n",
    "def get_fold_data(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "# Tensor conversion\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "\n",
    "def get_model(input_dim, hidden_dim, output_dim):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(in_features=input_dim, out_features=hidden_dim, bias=True),     # Input layer\n",
    "        torch.nn.Tanh(),                                                                # Activation function\n",
    "        torch.nn.Linear(in_features=hidden_dim, out_features=output_dim, bias=True),    # Output layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7b1ee",
   "metadata": {},
   "source": [
    "## 2 layer cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105cc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "outer_folds_k_1 = 10\n",
    "inner_folds_k_2 = 10\n",
    "random_state = 42\n",
    "\n",
    "# ANN parameters\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0\n",
    "hyperparameters_ANN = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # hidden layer sizes to try\n",
    "\n",
    "\n",
    "# Regularization parameters for linear regression\n",
    "lambdas__for_linear_regression = np.logspace(-4, 3, 30)[23:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5b41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 1 - Inner Fold 1\n",
      "Outer Fold 1 - Inner Fold 2\n",
      "Outer Fold 1 - Inner Fold 3\n",
      "Outer Fold 1 - Inner Fold 4\n",
      "Outer Fold 1 - Inner Fold 5\n",
      "Outer Fold 1 - Inner Fold 6\n",
      "Outer Fold 1 - Inner Fold 7\n",
      "Outer Fold 1 - Inner Fold 8\n",
      "Outer Fold 1 - Inner Fold 9\n",
      "Outer Fold 1 - Inner Fold 10\n",
      "For outer fold 1 Best λ (alpha): 188.73918221350996, Test MSE: 5212.335166348003\n",
      "For outer fold 1 Best hidden units: 2, Test MSE: 6283.1689\n",
      "For outer fold 1 Mean Inner fold MSE for Baseline: 5543.878799813896\n",
      "Outer Fold 2 - Inner Fold 1\n",
      "Outer Fold 2 - Inner Fold 2\n",
      "Outer Fold 2 - Inner Fold 3\n",
      "Outer Fold 2 - Inner Fold 4\n",
      "Outer Fold 2 - Inner Fold 5\n",
      "Outer Fold 2 - Inner Fold 6\n",
      "Outer Fold 2 - Inner Fold 7\n",
      "Outer Fold 2 - Inner Fold 8\n",
      "Outer Fold 2 - Inner Fold 9\n",
      "Outer Fold 2 - Inner Fold 10\n",
      "For outer fold 2 Best λ (alpha): 188.73918221350996, Test MSE: 5385.424082842444\n",
      "For outer fold 2 Best hidden units: 3, Test MSE: 5251.0757\n",
      "For outer fold 2 Mean Inner fold MSE for Baseline: 5599.172962415298\n",
      "Outer Fold 3 - Inner Fold 1\n",
      "Outer Fold 3 - Inner Fold 2\n",
      "Outer Fold 3 - Inner Fold 3\n",
      "Outer Fold 3 - Inner Fold 4\n",
      "Outer Fold 3 - Inner Fold 5\n",
      "Outer Fold 3 - Inner Fold 6\n",
      "Outer Fold 3 - Inner Fold 7\n",
      "Outer Fold 3 - Inner Fold 8\n",
      "Outer Fold 3 - Inner Fold 9\n",
      "Outer Fold 3 - Inner Fold 10\n",
      "For outer fold 3 Best λ (alpha): 188.73918221350996, Test MSE: 5628.0467150047425\n",
      "For outer fold 3 Best hidden units: 2, Test MSE: 5826.3438\n",
      "For outer fold 3 Mean Inner fold MSE for Baseline: 6384.788365740292\n",
      "Outer Fold 4 - Inner Fold 1\n",
      "Outer Fold 4 - Inner Fold 2\n",
      "Outer Fold 4 - Inner Fold 3\n",
      "Outer Fold 4 - Inner Fold 4\n",
      "Outer Fold 4 - Inner Fold 5\n",
      "Outer Fold 4 - Inner Fold 6\n",
      "Outer Fold 4 - Inner Fold 7\n",
      "Outer Fold 4 - Inner Fold 8\n",
      "Outer Fold 4 - Inner Fold 9\n",
      "Outer Fold 4 - Inner Fold 10\n",
      "For outer fold 4 Best λ (alpha): 188.73918221350996, Test MSE: 3842.0231366260114\n",
      "For outer fold 4 Best hidden units: 1, Test MSE: 4833.4971\n",
      "For outer fold 4 Mean Inner fold MSE for Baseline: 5103.847463873265\n",
      "Outer Fold 5 - Inner Fold 1\n",
      "Outer Fold 5 - Inner Fold 2\n",
      "Outer Fold 5 - Inner Fold 3\n",
      "Outer Fold 5 - Inner Fold 4\n",
      "Outer Fold 5 - Inner Fold 5\n",
      "Outer Fold 5 - Inner Fold 6\n",
      "Outer Fold 5 - Inner Fold 7\n",
      "Outer Fold 5 - Inner Fold 8\n",
      "Outer Fold 5 - Inner Fold 9\n",
      "Outer Fold 5 - Inner Fold 10\n",
      "For outer fold 5 Best λ (alpha): 188.73918221350996, Test MSE: 4277.956947984186\n",
      "For outer fold 5 Best hidden units: 2, Test MSE: 4860.2983\n",
      "For outer fold 5 Mean Inner fold MSE for Baseline: 4707.1240511693695\n",
      "Outer Fold 6 - Inner Fold 1\n",
      "Outer Fold 6 - Inner Fold 2\n",
      "Outer Fold 6 - Inner Fold 3\n",
      "Outer Fold 6 - Inner Fold 4\n",
      "Outer Fold 6 - Inner Fold 5\n",
      "Outer Fold 6 - Inner Fold 6\n",
      "Outer Fold 6 - Inner Fold 7\n",
      "Outer Fold 6 - Inner Fold 8\n",
      "Outer Fold 6 - Inner Fold 9\n",
      "Outer Fold 6 - Inner Fold 10\n",
      "For outer fold 6 Best λ (alpha): 108.2636733874054, Test MSE: 6034.490574168974\n",
      "For outer fold 6 Best hidden units: 1, Test MSE: 5779.7583\n",
      "For outer fold 6 Mean Inner fold MSE for Baseline: 6811.592483980782\n",
      "Outer Fold 7 - Inner Fold 1\n",
      "Outer Fold 7 - Inner Fold 2\n",
      "Outer Fold 7 - Inner Fold 3\n",
      "Outer Fold 7 - Inner Fold 4\n",
      "Outer Fold 7 - Inner Fold 5\n",
      "Outer Fold 7 - Inner Fold 6\n",
      "Outer Fold 7 - Inner Fold 7\n",
      "Outer Fold 7 - Inner Fold 8\n",
      "Outer Fold 7 - Inner Fold 9\n",
      "Outer Fold 7 - Inner Fold 10\n",
      "For outer fold 7 Best λ (alpha): 188.73918221350996, Test MSE: 6270.301262739458\n",
      "For outer fold 7 Best hidden units: 8, Test MSE: 6579.1411\n",
      "For outer fold 7 Mean Inner fold MSE for Baseline: 6991.245497344335\n",
      "Outer Fold 8 - Inner Fold 1\n",
      "Outer Fold 8 - Inner Fold 2\n",
      "Outer Fold 8 - Inner Fold 3\n",
      "Outer Fold 8 - Inner Fold 4\n",
      "Outer Fold 8 - Inner Fold 5\n",
      "Outer Fold 8 - Inner Fold 6\n",
      "Outer Fold 8 - Inner Fold 7\n",
      "Outer Fold 8 - Inner Fold 8\n",
      "Outer Fold 8 - Inner Fold 9\n",
      "Outer Fold 8 - Inner Fold 10\n",
      "For outer fold 8 Best λ (alpha): 108.2636733874054, Test MSE: 8159.409191472006\n",
      "For outer fold 8 Best hidden units: 2, Test MSE: 7790.1646\n",
      "For outer fold 8 Mean Inner fold MSE for Baseline: 7346.2819962871345\n",
      "Outer Fold 9 - Inner Fold 1\n",
      "Outer Fold 9 - Inner Fold 2\n",
      "Outer Fold 9 - Inner Fold 3\n",
      "Outer Fold 9 - Inner Fold 4\n",
      "Outer Fold 9 - Inner Fold 5\n",
      "Outer Fold 9 - Inner Fold 6\n",
      "Outer Fold 9 - Inner Fold 7\n",
      "Outer Fold 9 - Inner Fold 8\n",
      "Outer Fold 9 - Inner Fold 9\n",
      "Outer Fold 9 - Inner Fold 10\n",
      "For outer fold 9 Best λ (alpha): 188.73918221350996, Test MSE: 6520.9251651993545\n",
      "For outer fold 9 Best hidden units: 1, Test MSE: 6147.5571\n",
      "For outer fold 9 Mean Inner fold MSE for Baseline: 5970.658637940327\n",
      "Outer Fold 10 - Inner Fold 1\n",
      "Outer Fold 10 - Inner Fold 2\n",
      "Outer Fold 10 - Inner Fold 3\n",
      "Outer Fold 10 - Inner Fold 4\n",
      "Outer Fold 10 - Inner Fold 5\n",
      "Outer Fold 10 - Inner Fold 6\n",
      "Outer Fold 10 - Inner Fold 7\n",
      "Outer Fold 10 - Inner Fold 8\n",
      "Outer Fold 10 - Inner Fold 9\n",
      "Outer Fold 10 - Inner Fold 10\n",
      "For outer fold 10 Best λ (alpha): 188.73918221350996, Test MSE: 5247.498704316543\n",
      "For outer fold 10 Best hidden units: 1, Test MSE: 5369.8491\n",
      "For outer fold 10 Mean Inner fold MSE for Baseline: 5815.648143891019\n"
     ]
    }
   ],
   "source": [
    "CV_outer = KFold(n_splits=outer_folds_k_1, shuffle=True, random_state=random_state) \n",
    "\n",
    "baseline_per_fold = {}   # Outer fold dict (key: outer fold index)\n",
    "best_hyperparameters_per_fold = {}\n",
    "best_lambda_per_fold = {}\n",
    "fold_results = {}\n",
    "outer_fold_index = 0\n",
    "\n",
    "for outer_train_idx, outer_test_idx in CV_outer.split(X):\n",
    "    outer_fold_index += 1\n",
    "    X_train_outer, X_test_outer, y_train_outer, y_test_outer = get_fold_data(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    CV_inner = KFold(n_splits=inner_folds_k_2, shuffle=True, random_state=random_state)\n",
    "    inner_mse_ANN = {}\n",
    "    inner_mse_linear_regression = {}\n",
    "    inner_fold_index = 0\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in CV_inner.split(X_train_outer):\n",
    "        inner_fold_index += 1\n",
    "        print(f\"Outer Fold {outer_fold_index} - Inner Fold {inner_fold_index}\")\n",
    "\n",
    "        ############################# DATA Inner Fold ####################################\n",
    "        X_train_inner_norm, X_test_inner_norm, y_train_inner_norm, y_test_inner_norm = get_fold_data_normalized(X_train_outer, y_train_outer, inner_train_idx, inner_test_idx)\n",
    "\n",
    "        ############################# Linear Regression Inner Fold ####################################\n",
    "        \n",
    "        # Set up a dictionary to store the results for each lambda setting\n",
    "        results_inner_linear_regression = {lam: {'train': [], 'test': []} for lam in lambdas__for_linear_regression}\n",
    "\n",
    "        for lam in lambdas__for_linear_regression:\n",
    "\n",
    "            model = Ridge(alpha=lam, random_state=42)\n",
    "            model.fit(X_train_inner_norm, y_train_inner_norm)\n",
    "\n",
    "            y_test_pred_inner = model.predict(X_test_inner_norm)\n",
    "            mse_test = mean_squared_error(y_test_inner_norm, y_test_pred_inner)\n",
    "\n",
    "            results_inner_linear_regression[lam]['test'].append(mse_test)\n",
    "            inner_mse_linear_regression[inner_fold_index] = results_inner_linear_regression\n",
    "\n",
    "        ############################# ANN Inner Fold ########################################\n",
    "        X_train_inner_tensor, y_train_inner_tensor, X_test_inner_tensor, y_test_inner_tensor = torch_tensor_conversion(X_train_inner_norm, y_train_inner_norm, X_test_inner_norm, y_test_inner_norm) \n",
    "    \n",
    "        # Set up a dictionary to store the results for each hyperparameter setting\n",
    "        results_inner_ANN = {hidden_dim: {'train': [], 'test': []} for hidden_dim in hyperparameters_ANN}\n",
    "\n",
    "        for hidden_dim in hyperparameters_ANN:\n",
    "            # Define a model instance with a specific number of hidden units\n",
    "            model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "            # Define loss criterion\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "            optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "\n",
    "                # Set the model to training mode\n",
    "                model.train()\n",
    "\n",
    "                # Make a forward pass through the model to compute the outputs\n",
    "                outputs = model(X_train_inner_tensor)\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, y_train_inner_tensor)\n",
    "\n",
    "                # Make sure that the gradients are zero before you use backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "                loss.backward()\n",
    "                # Update the model parameters by making the optimizer take a gradient descent step\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Store the training loss for this epoch in the dictionary\n",
    "                #results_inner_ANN[hidden_dim]['train'].append(loss.item())\n",
    "\n",
    "            # Compute the final test loss on the test set\n",
    "            with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "                model.eval()\n",
    "                val_outputs = model(X_test_inner_tensor)\n",
    "                val_loss = criterion(val_outputs, y_test_inner_tensor)\n",
    "                results_inner_ANN[hidden_dim]['test'].append(val_loss.item())\n",
    "                #print(f'  Hidden units: {hidden_dim}, Validation set MSE: {val_loss.item():.4f}')\n",
    "                inner_mse_ANN[inner_fold_index] = results_inner_ANN \n",
    "\n",
    "        ############################# BASELINE Inner Fold ####################################\n",
    "\n",
    "        #----\n",
    "\n",
    "    ############################ OUTER FOLD ##########################################################\n",
    "\n",
    "    ############################ Data ##########################################################\n",
    "\n",
    "    X_train_outer_norm, X_test_outer_norm, y_train_outer_norm, y_test_outer_norm = get_fold_data_normalized(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    X_train_outer_tensor, y_train_outer_tensor, X_test_outer_tensor, y_test_outer_tensor = torch_tensor_conversion(X_train_outer_norm, y_train_outer_norm, X_test_outer_norm, y_test_outer_norm)\n",
    "\n",
    "    ############################ Linear Regression Outer Fold ####################################\n",
    "\n",
    "    avg_mse_per_lambda = {}\n",
    "    for lam in lambdas__for_linear_regression:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_linear_regression.keys():\n",
    "            mse_values.append(inner_mse_linear_regression[inner_fold][lam]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_lambda[lam] = avg_mse\n",
    "    \n",
    "    best_lambda = min(avg_mse_per_lambda, key=avg_mse_per_lambda.get)\n",
    "    best_lambda_per_fold[outer_fold_index] = best_lambda\n",
    "\n",
    "    model = Ridge(alpha=best_lambda, random_state=42)\n",
    "    model.fit(X_train_outer_norm, y_train_outer_norm)\n",
    "    y_test_pred_outer = model.predict(X_test_outer_norm)\n",
    "    mse_test_outer = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "    print(f\"For outer fold {outer_fold_index} Best λ (alpha): {best_lambda}, Test MSE: {mse_test_outer}\")\n",
    "\n",
    "    ############################ ANN Outer Fold ####################################\n",
    "    # Find the best hyperparameter based on inner folds\n",
    "    avg_mse_per_hyperparam = {}\n",
    "    for hidden_dim in hyperparameters_ANN:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_ANN.keys():\n",
    "            mse_values.append(inner_mse_ANN[inner_fold][hidden_dim]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_hyperparam[hidden_dim] = avg_mse\n",
    "        \n",
    "    \n",
    "    best_hyperparam = min(avg_mse_per_hyperparam, key=avg_mse_per_hyperparam.get)\n",
    "    best_hyperparameters_per_fold[outer_fold_index] = best_hyperparam\n",
    "\n",
    "\n",
    "    model = get_model(input_dim=input_dim, hidden_dim=best_hyperparam, output_dim=output_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        outputs = model(X_train_outer_tensor)\n",
    "        loss = criterion(outputs, y_train_outer_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_outer_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_outer_tensor)\n",
    "            print(f'For outer fold {outer_fold_index} Best hidden units: {best_hyperparam}, Test MSE: {val_loss.item():.4f}')\n",
    "    \n",
    "    ############################ BASELINE Outer Fold ###############################\n",
    "\n",
    "    y_train_mean = y_train_outer_norm.mean()\n",
    "    y_test_pred_outer = pd.Series(y_train_mean, index=y_test_outer_norm.index)\n",
    "    outer_mse_baseline = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "    baseline_per_fold[outer_fold_index] = outer_mse_baseline \n",
    "    print(f\"For outer fold {outer_fold_index} Mean Inner fold MSE for Baseline:\", outer_mse_baseline)\n",
    "\n",
    "    ############################# STORE RESULTS ####################################\n",
    "\n",
    "    fold_results[outer_fold_index] = {\n",
    "        \"linear_regression_best_lambda\": best_lambda,\n",
    "        \"linear_regression_mse\": mse_test_outer,\n",
    "        \"ANN_best_hidden_units\": best_hyperparam,\n",
    "        \"ANN_mse\": val_loss.item(),\n",
    "        \"baseline_outer_mse\": outer_mse_baseline\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e50922",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3f436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_best_parameters(dict_parameters_for_each_outer_fold):\n",
    "    count_parameter_dict = {}\n",
    "    for outer_fold_index in dict_parameters_for_each_outer_fold.keys():\n",
    "        if dict_parameters_for_each_outer_fold.get(outer_fold_index) not in count_parameter_dict.keys() :\n",
    "            count_parameter_dict[dict_parameters_for_each_outer_fold.get(outer_fold_index)] = 1\n",
    "\n",
    "        else:\n",
    "            count_parameter_dict[dict_parameters_for_each_outer_fold.get(outer_fold_index)] += 1\n",
    "\n",
    "    return count_parameter_dict\n",
    "\n",
    "def best_parameter(count_parameter_dict):\n",
    "    best_param = max(count_parameter_dict, key=count_parameter_dict.get)\n",
    "    return best_param\n",
    "\n",
    "best_lambda = best_parameter(count_best_parameters(best_lambda_per_fold))\n",
    "best_hyperparameter = best_parameter(count_best_parameters(best_hyperparameters_per_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af694643",
   "metadata": {},
   "source": [
    "### learning_rate = 0.001, momentum = 0, n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d6fbc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "learning_rate = 0.001, momentum = 0, n_epochs = 1000\n",
      "Mean ANN MSE across outer folds: 5872.085400390625\n",
      "Mean difference between baseline and ANN MSE across outer folds: 155.33843985494667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_regression_best_lambda</th>\n",
       "      <th>linear_regression_mse</th>\n",
       "      <th>ANN_best_hidden_units</th>\n",
       "      <th>ANN_mse</th>\n",
       "      <th>baseline_outer_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5212.335166</td>\n",
       "      <td>2</td>\n",
       "      <td>6283.168945</td>\n",
       "      <td>5543.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5385.424083</td>\n",
       "      <td>3</td>\n",
       "      <td>5251.075684</td>\n",
       "      <td>5599.172962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5628.046715</td>\n",
       "      <td>2</td>\n",
       "      <td>5826.343750</td>\n",
       "      <td>6384.788366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>3842.023137</td>\n",
       "      <td>1</td>\n",
       "      <td>4833.497070</td>\n",
       "      <td>5103.847464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>4277.956948</td>\n",
       "      <td>2</td>\n",
       "      <td>4860.298340</td>\n",
       "      <td>4707.124051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>6034.490574</td>\n",
       "      <td>1</td>\n",
       "      <td>5779.758301</td>\n",
       "      <td>6811.592484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6270.301263</td>\n",
       "      <td>8</td>\n",
       "      <td>6579.141113</td>\n",
       "      <td>6991.245497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>8159.409191</td>\n",
       "      <td>2</td>\n",
       "      <td>7790.164551</td>\n",
       "      <td>7346.281996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6520.925165</td>\n",
       "      <td>1</td>\n",
       "      <td>6147.557129</td>\n",
       "      <td>5970.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5247.498704</td>\n",
       "      <td>1</td>\n",
       "      <td>5369.849121</td>\n",
       "      <td>5815.648144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_regression_best_lambda  linear_regression_mse  \\\n",
       "1                      188.739182            5212.335166   \n",
       "2                      188.739182            5385.424083   \n",
       "3                      188.739182            5628.046715   \n",
       "4                      188.739182            3842.023137   \n",
       "5                      188.739182            4277.956948   \n",
       "6                      108.263673            6034.490574   \n",
       "7                      188.739182            6270.301263   \n",
       "8                      108.263673            8159.409191   \n",
       "9                      188.739182            6520.925165   \n",
       "10                     188.739182            5247.498704   \n",
       "\n",
       "    ANN_best_hidden_units      ANN_mse  baseline_outer_mse  \n",
       "1                       2  6283.168945         5543.878800  \n",
       "2                       3  5251.075684         5599.172962  \n",
       "3                       2  5826.343750         6384.788366  \n",
       "4                       1  4833.497070         5103.847464  \n",
       "5                       2  4860.298340         4707.124051  \n",
       "6                       1  5779.758301         6811.592484  \n",
       "7                       8  6579.141113         6991.245497  \n",
       "8                       2  7790.164551         7346.281996  \n",
       "9                       1  6147.557129         5970.658638  \n",
       "10                      1  5369.849121         5815.648144  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(f\"learning_rate = {lr}, momentum = {momentum}, n_epochs = {n_epochs}\")\n",
    "mean_ANN_mse = outer_results_df['ANN_mse'].mean()\n",
    "difference_ANN_mse_baseline_mse = (outer_results_df['baseline_outer_mse'] - outer_results_df['ANN_mse']).mean()\n",
    "print(f\"Mean ANN MSE across outer folds: {mean_ANN_mse}\")\n",
    "print(f\"Mean difference between baseline and ANN MSE across outer folds: {difference_ANN_mse_baseline_mse}\")\n",
    "outer_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ (alpha) for Linear Regression across all outer folds: 188.73918221350996\n",
      "Best hidden units for ANN across all outer folds: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Best λ (alpha) for Linear Regression across all outer folds:\", best_lambda)\n",
    "print(\"Best hidden units for ANN across all outer folds:\", best_hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b20091",
   "metadata": {},
   "source": [
    "# Statistical Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ab9e3",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d2aa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_ttest(r, rho, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform a correlated t-test to compare two models under Setup II.\n",
    "\n",
    "    Parameters:\n",
    "    - r (array-like): Array of performance differences across folds (e.g. r_j = error_A - error_B)\n",
    "    - rho (float): Correlation coefficient between folds (typically 1/K for K-fold CV)\n",
    "    - alpha (float, optional): Significance level (default: 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - p (float): p-value of the test\n",
    "    - CI (tuple): Confidence interval for the mean difference\n",
    "    \"\"\"\n",
    "\n",
    "    r = np.array(r)\n",
    "    r_hat = np.mean(r)\n",
    "    s_hat = np.std(r, ddof=1)\n",
    "    J = len(r)\n",
    "\n",
    "    # Adjusted standard deviation accounting for correlation\n",
    "    sigma_tilde = s_hat * np.sqrt((1 / J) + (rho / (1 - rho)))\n",
    "\n",
    "    # Confidence interval\n",
    "    CI = st.t.interval(1 - alpha, df=J - 1, loc=r_hat, scale=sigma_tilde)\n",
    "\n",
    "    # Two-sided p-value\n",
    "    p = 2 * st.t.cdf(-np.abs(r_hat) / sigma_tilde, df=J - 1)\n",
    "\n",
    "    return r_hat, CI, p\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf06ee4",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10 # Repetitions\n",
    "K = 10 # Folds\n",
    "rho = 1 / K # Correlation heuristic\n",
    "alpha = 0.05 # Significance level\n",
    "\n",
    "# ANN parameters\n",
    "\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0.9\n",
    "\n",
    "#Loss Function \n",
    "l2_loss = lambda y, y_pred: (y - y_pred)**2\n",
    "loss_func = l2_loss # Loss function\n",
    "\n",
    "# Parameters used\n",
    "\n",
    "best_lambda_statistic_test = best_lambda\n",
    "best_hyperparameter_statistic_test = best_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c9370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.73918221350996\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(best_lambda_statistic_test)\n",
    "print(best_hyperparameter_statistic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d4075",
   "metadata": {},
   "source": [
    "### ANN vs Linear Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefc8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -2096.0713\n",
      "95% CI: [-3119.0039, -1073.1387]\n",
      "p-value: 9.612268361027621e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = Ridge(alpha = best_lambda_statistic_test, random_state=repeat_idx)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg).values.flatten()  # Get individual squared errors as a 1D array\n",
    "\n",
    "        ##################################################### ANN MODEL #################################################\n",
    "\n",
    "        model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "        # Define loss criterion - set reduction to 'none' to get individual errors\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Make a forward pass through the model to compute the outputs\n",
    "            outputs = model(X_train_tensor)\n",
    "            # Compute the loss (this will still be a tensor of individual losses, so take mean for backward)\n",
    "            loss = criterion(outputs, y_train_tensor).mean()  # mean needed for backward\n",
    "\n",
    "            # Make sure that the gradients are zero before you use backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "            loss.backward()\n",
    "            # Update the model parameters by making the optimizer take a gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_losses = criterion(val_outputs, y_test_tensor)  # Tensor of individual squared errors\n",
    "            loss_func_ANN = val_losses.detach().cpu().numpy().flatten()  # Convert to numpy array for all individual errors\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "\n",
    "        r_j = np.mean(loss_func_linear_reg - loss_func_ANN)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a30d7",
   "metadata": {},
   "source": [
    "### ANN vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cdef24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -1702.1377\n",
      "95% CI: [-2884.7257, -519.5497]\n",
      "p-value: 0.005228657379418414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline).values.flatten()\n",
    "\n",
    "        ##################################################### ANN MODEL #################################################\n",
    "\n",
    "        model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "        # Define loss criterion - set reduction to 'none' to get individual errors\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Make a forward pass through the model to compute the outputs\n",
    "            outputs = model(X_train_tensor)\n",
    "            # Compute the loss (this will still be a tensor of individual losses, so take mean for backward)\n",
    "            loss = criterion(outputs, y_train_tensor).mean()  # mean needed for backward\n",
    "\n",
    "            # Make sure that the gradients are zero before you use backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "            loss.backward()\n",
    "            # Update the model parameters by making the optimizer take a gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_losses = criterion(val_outputs, y_test_tensor)  # Tensor of individual squared errors\n",
    "            loss_func_ANN = val_losses.detach().cpu().numpy().flatten()  # Convert to numpy array for all individual errors\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "\n",
    "        r_j = np.mean(loss_funcion_baseline - loss_func_ANN)\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f77d6",
   "metadata": {},
   "source": [
    "### Linear Reg vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a65bcdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 350.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 432.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 445.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 441.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 435.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 449.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 448.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 463.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 448.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 443.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -355.4150\n",
      "95% CI: [-693.7043, -17.1256]\n",
      "p-value: 0.03967328811249884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = Ridge(alpha = best_lambda_statistic_test, random_state=repeat_idx)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline)\n",
    "\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "        \n",
    "        r_j = np.mean(loss_func_linear_reg - loss_funcion_baseline)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
