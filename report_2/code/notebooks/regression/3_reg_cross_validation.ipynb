{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8242ed63",
   "metadata": {},
   "source": [
    "# reg_part_B_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ba25",
   "metadata": {},
   "source": [
    "# Data import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c13ac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data_file=\"heart_failure_clinical_records_dataset\"\n",
    "\n",
    "data = pd.read_csv(f\"../../raw_data/{name_data_file}.csv\", na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac829f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0    75.0        0                       582         0                 20   \n",
       "1    55.0        0                      7861         0                 38   \n",
       "2    65.0        0                       146         0                 20   \n",
       "3    50.0        1                       111         0                 20   \n",
       "4    65.0        1                       160         1                 20   \n",
       "..    ...      ...                       ...       ...                ...   \n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      1  265000.00               1.9           130    1   \n",
       "1                      0  263358.03               1.1           136    1   \n",
       "2                      0  162000.00               1.3           129    1   \n",
       "3                      0  210000.00               1.9           137    1   \n",
       "4                      0  327000.00               2.7           116    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "294                    1  155000.00               1.1           143    1   \n",
       "295                    0  270000.00               1.2           139    0   \n",
       "296                    0  742000.00               0.8           138    0   \n",
       "297                    0  140000.00               1.4           140    1   \n",
       "298                    0  395000.00               1.6           136    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "0          0     4            1  \n",
       "1          0     6            1  \n",
       "2          1     7            1  \n",
       "3          0     7            1  \n",
       "4          0     8            1  \n",
       "..       ...   ...          ...  \n",
       "294        1   270            0  \n",
       "295        0   271            0  \n",
       "296        0   278            0  \n",
       "297        1   280            0  \n",
       "298        1   285            0  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598f101",
   "metadata": {},
   "source": [
    "# Cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "5c41e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['time'])\n",
    "y = data['time']   # pandas Series\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "# X.shape, y.shape print shapes of X and y to undestand their dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3341fec",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "86e127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data based on training set\n",
    "\n",
    "def get_fold_data(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "# Tensor conversion\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "\n",
    "def get_model(input_dim, hidden_dim, output_dim):\n",
    "    ### BEGIN SOLUTION\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(in_features=input_dim, out_features=hidden_dim, bias=True),     # Input layer\n",
    "        torch.nn.Tanh(),                                                                # Activation function\n",
    "        torch.nn.Linear(in_features=hidden_dim, out_features=output_dim, bias=True),    # Output layer\n",
    "    )\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7b1ee",
   "metadata": {},
   "source": [
    "## 2 layer cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "105cc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "\n",
    "outer_folds_k_1 = 3\n",
    "inner_folds_k_2 = 3\n",
    "random_state = 42\n",
    "\n",
    "# ANN parameters\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 10000\n",
    "momentum = 0.4\n",
    "hyperparameters_ANN = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "# Regularization parameters for linear regression\n",
    "lambdas__for_linear_regression = np.logspace(-4, 3, 30)[20:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "1a5b41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 1 - Inner Fold 1\n",
      "Outer Fold 1 - Inner Fold 2\n",
      "Outer Fold 1 - Inner Fold 3\n",
      "For outer fold 1 Best λ (alpha): 35.622478902624444, Test MSE: 4061.6333422755097\n",
      "For outer fold 1 Best hidden units: 6, Test MSE: 6015.5537\n",
      "For outer fold 1 Mean Inner fold MSE for Baseline: 6027.190356304133\n",
      "Outer Fold 2 - Inner Fold 1\n",
      "Outer Fold 2 - Inner Fold 2\n",
      "Outer Fold 2 - Inner Fold 3\n",
      "For outer fold 2 Best λ (alpha): 35.622478902624444, Test MSE: 3968.733811360825\n",
      "For outer fold 2 Best hidden units: 6, Test MSE: 5886.3442\n",
      "For outer fold 2 Mean Inner fold MSE for Baseline: 5897.27\n",
      "Outer Fold 3 - Inner Fold 1\n",
      "Outer Fold 3 - Inner Fold 2\n",
      "Outer Fold 3 - Inner Fold 3\n",
      "For outer fold 3 Best λ (alpha): 35.622478902624444, Test MSE: 5204.552586091692\n",
      "For outer fold 3 Best hidden units: 4, Test MSE: 6207.4180\n",
      "For outer fold 3 Mean Inner fold MSE for Baseline: 6211.524629040404\n"
     ]
    }
   ],
   "source": [
    "CV_outer = KFold(n_splits=outer_folds_k_1, shuffle=True, random_state=random_state) \n",
    "\n",
    "baseline_per_fold = {}   # Outer fold dict (key: outer fold index)\n",
    "best_hyperparameters_per_fold = {}\n",
    "best_lambda_per_fold = {}\n",
    "outer_fold_index = 0\n",
    "\n",
    "for outer_train_idx, outer_test_idx in CV_outer.split(X):\n",
    "    outer_fold_index += 1\n",
    "    X_train_outer, X_test_outer, y_train_outer, y_test_outer = get_fold_data(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    CV_inner = KFold(n_splits=inner_folds_k_2, shuffle=True, random_state=random_state)\n",
    "    inner_mse_ANN = {}\n",
    "    inner_mse_linear_regression = {}\n",
    "    inner_fold_index = 0\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in CV_inner.split(X_train_outer):\n",
    "        inner_fold_index += 1\n",
    "        print(f\"Outer Fold {outer_fold_index} - Inner Fold {inner_fold_index}\")\n",
    "\n",
    "        ############################# DATA Inner Fold ####################################\n",
    "        X_train_inner_norm, X_test_inner_norm, y_train_inner_norm, y_test_inner_norm = get_fold_data_normalized(X_train_outer, y_train_outer, inner_train_idx, inner_test_idx)\n",
    "\n",
    "        ############################# Linear Regression Inner Fold ####################################\n",
    "        \n",
    "        # Set up a dictionary to store the results for each lambda setting\n",
    "        results_inner_linear_regression = {lam: {'train': [], 'test': []} for lam in lambdas__for_linear_regression}\n",
    "\n",
    "        for lam in lambdas__for_linear_regression:\n",
    "\n",
    "            model = Ridge(alpha=lam, random_state=42)\n",
    "            model.fit(X_train_inner_norm, y_train_inner_norm)\n",
    "\n",
    "            y_test_pred_inner = model.predict(X_test_inner_norm)\n",
    "            mse_test = mean_squared_error(y_test_inner_norm, y_test_pred_inner)\n",
    "\n",
    "            results_inner_linear_regression[lam]['test'].append(mse_test)\n",
    "            inner_mse_linear_regression[inner_fold_index] = results_inner_linear_regression\n",
    "\n",
    "        ############################# ANN Inner Fold ########################################\n",
    "        X_train_inner_tensor, y_train_inner_tensor, X_test_inner_tensor, y_test_inner_tensor = torch_tensor_conversion(X_train_inner_norm, y_train_inner_norm, X_test_inner_norm, y_test_inner_norm) \n",
    "    \n",
    "        # Set up a dictionary to store the results for each hyperparameter setting\n",
    "        results_inner_ANN = {hidden_dim: {'train': [], 'test': []} for hidden_dim in hyperparameters_ANN}\n",
    "\n",
    "        for hidden_dim in hyperparameters_ANN:\n",
    "            # Define a model instance with a specific number of hidden units\n",
    "            model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "            # Define loss criterion\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "            optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "\n",
    "                # Set the model to training mode\n",
    "                model.train()\n",
    "\n",
    "                # Make a forward pass through the model to compute the outputs\n",
    "                outputs = model(X_train_inner_tensor)\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, y_train_inner_tensor)\n",
    "\n",
    "                # Make sure that the gradients are zero before you use backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "                loss.backward()\n",
    "                # Update the model parameters by making the optimizer take a gradient descent step\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Store the training loss for this epoch in the dictionary\n",
    "                #results_inner_ANN[hidden_dim]['train'].append(loss.item())\n",
    "\n",
    "            # Compute the final test loss on the test set\n",
    "            with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "                model.eval()\n",
    "                val_outputs = model(X_test_inner_tensor)\n",
    "                val_loss = criterion(val_outputs, y_test_inner_tensor)\n",
    "                results_inner_ANN[hidden_dim]['test'].append(val_loss.item())\n",
    "                #print(f'  Hidden units: {hidden_dim}, Validation set MSE: {val_loss.item():.4f}')\n",
    "                inner_mse_ANN[inner_fold_index] = results_inner_ANN \n",
    "\n",
    "        ############################# BASELINE Inner Fold ####################################\n",
    "\n",
    "        #----\n",
    "\n",
    "\n",
    "    ############################ OUTER FOLD ##########################################################\n",
    "\n",
    "    ############################ Data ##########################################################\n",
    "\n",
    "    X_train_outer_norm, X_test_outer_norm, y_train_outer_norm, y_test_outer_norm = get_fold_data_normalized(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    X_train_outer_tensor, y_train_outer_tensor, X_test_outer_tensor, y_test_outer_tensor = torch_tensor_conversion(X_train_outer_norm, y_train_outer_norm, X_test_outer_norm, y_test_outer_norm)\n",
    "\n",
    "    ############################ Linear Regression Outer Fold ####################################\n",
    "\n",
    "    avg_mse_per_lambda = {}\n",
    "    for lam in lambdas__for_linear_regression:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_linear_regression.keys():\n",
    "            mse_values.append(inner_mse_linear_regression[inner_fold][lam]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_lambda[lam] = avg_mse\n",
    "    \n",
    "    best_lambda = min(avg_mse_per_lambda, key=avg_mse_per_lambda.get)\n",
    "    best_lambda_per_fold[outer_fold_index] = best_lambda\n",
    "\n",
    "    model = Ridge(alpha=best_lambda, random_state=42)\n",
    "    model.fit(X_train_outer_norm, y_train_outer_norm)\n",
    "    y_test_pred_outer = model.predict(X_test_outer_norm)\n",
    "    mse_test_outer = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "    print(f\"For outer fold {outer_fold_index} Best λ (alpha): {best_lambda}, Test MSE: {mse_test_outer}\")\n",
    "\n",
    "    ############################ ANN Outer Fold ####################################\n",
    "    # Find the best hyperparameter based on inner folds\n",
    "    avg_mse_per_hyperparam = {}\n",
    "    for hidden_dim in hyperparameters_ANN:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_ANN.keys():\n",
    "            mse_values.append(inner_mse_ANN[inner_fold][hidden_dim]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_hyperparam[hidden_dim] = avg_mse\n",
    "    \n",
    "    best_hyperparam = min(avg_mse_per_hyperparam, key=avg_mse_per_hyperparam.get)\n",
    "    best_hyperparameters_per_fold[outer_fold_index] = best_hyperparam\n",
    "\n",
    "    model = get_model(input_dim=input_dim, hidden_dim=best_hyperparam, output_dim=output_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "    model.train()\n",
    "    outputs = model(X_train_outer_tensor)\n",
    "    loss = criterion(outputs, y_train_outer_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_outer_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_outer_tensor)\n",
    "            print(f'For outer fold {outer_fold_index} Best hidden units: {best_hyperparam}, Test MSE: {val_loss.item():.4f}')\n",
    "    \n",
    "    ############################ BASELINE Outer Fold ###############################\n",
    "\n",
    "    y_train_mean = y_train_outer_norm.mean()\n",
    "    y_test_pred_outer = pd.Series(y_train_mean, index=y_test_outer_norm.index)\n",
    "    outer_mse_baseline = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "    baseline_per_fold[outer_fold_index] = outer_mse_baseline \n",
    "    print(f\"For outer fold {outer_fold_index} Mean Inner fold MSE for Baseline:\", outer_mse_baseline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "39538fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_best_parameters(dict_parameters_for_each_outer_fold):\n",
    "    count_parameter_dict = {}\n",
    "    for outer_fold_index in dict_parameters_for_each_outer_fold.keys():\n",
    "        if dict_parameters_for_each_outer_fold.get(outer_fold_index) not in count_parameter_dict.keys() :\n",
    "            count_parameter_dict[dict_parameters_for_each_outer_fold.get(outer_fold_index)] = 1\n",
    "\n",
    "        else:\n",
    "            count_parameter_dict[dict_parameters_for_each_outer_fold.get(outer_fold_index)] += 1\n",
    "\n",
    "    return count_parameter_dict\n",
    "\n",
    "def best_parameter(count_parameter_dict):\n",
    "    best_param = max(count_parameter_dict, key=count_parameter_dict.get)\n",
    "    return best_param\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d573ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ (alpha) for Linear Regression across all outer folds: 35.622478902624444\n",
      "Best hidden units for ANN across all outer folds: 4\n"
     ]
    }
   ],
   "source": [
    "best_lambda = best_parameter(count_best_parameters(best_lambda_per_fold))\n",
    "best_hyperparameter = best_parameter(count_best_parameters(best_hyperparameters_per_fold))\n",
    "    \n",
    "print(\"Best λ (alpha) for Linear Regression across all outer folds:\", best_lambda)\n",
    "print(\"Best hidden units for ANN across all outer folds:\", best_hyperparam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b20091",
   "metadata": {},
   "source": [
    "# Statistical Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ab9e3",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0d2aa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_ttest(r, rho, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform a correlated t-test to compare two models under Setup II.\n",
    "\n",
    "    Parameters:\n",
    "    - r (array-like): Array of performance differences across folds (e.g. r_j = error_A - error_B)\n",
    "    - rho (float): Correlation coefficient between folds (typically 1/K for K-fold CV)\n",
    "    - alpha (float, optional): Significance level (default: 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - p (float): p-value of the test\n",
    "    - CI (tuple): Confidence interval for the mean difference\n",
    "    \"\"\"\n",
    "\n",
    "    r = np.array(r)\n",
    "    r_hat = np.mean(r)\n",
    "    s_hat = np.std(r, ddof=1)\n",
    "    J = len(r)\n",
    "\n",
    "    # Adjusted standard deviation accounting for correlation\n",
    "    sigma_tilde = s_hat * np.sqrt((1 / J) + (rho / (1 - rho)))\n",
    "\n",
    "    # Confidence interval\n",
    "    CI = st.t.interval(1 - alpha, df=J - 1, loc=r_hat, scale=sigma_tilde)\n",
    "\n",
    "    # Two-sided p-value\n",
    "    p = 2 * st.t.cdf(-np.abs(r_hat) / sigma_tilde, df=J - 1)\n",
    "\n",
    "    return r_hat, CI, p\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf06ee4",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10 # Repetitions\n",
    "K = 10 # Folds\n",
    "rho = 1 / K # Correlation heuristic\n",
    "alpha = 0.05 # Significance level\n",
    "\n",
    "# ANN parameters\n",
    "\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0.9\n",
    "\n",
    "#Loss Function \n",
    "l2_loss = lambda y, y_pred: (y - y_pred)**2\n",
    "loss_func = l2_loss # Loss function\n",
    "\n",
    "# Parameters used\n",
    "\n",
    "best_lambda_statistic_test = best_lambda\n",
    "best_hyperparameter_statistic_test = best_hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d4075",
   "metadata": {},
   "source": [
    "### ANN vs Linear Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "eefc8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -1071.1351\n",
      "95% CI: [-1678.1154, -464.1548]\n",
      "p-value: 0.0006954886522411656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = Ridge(alpha = best_lambda_statistic_test, random_state=repeat_idx)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg)\n",
    "\n",
    "        ##################################################### ANN MODEL #################################################\n",
    "\n",
    "        model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "        # Define loss criterion\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Make a forward pass through the model to compute the outputs\n",
    "            outputs = model(X_train_inner_tensor)\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, y_train_inner_tensor)\n",
    "\n",
    "            # Make sure that the gradients are zero before you use backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "            loss.backward()\n",
    "            # Update the model parameters by making the optimizer take a gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_inner_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_inner_tensor)\n",
    "            loss_func_linear_ANN = val_loss.item()\n",
    "\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "\n",
    "        r_j = np.mean(loss_func_linear_reg - loss_func_linear_ANN)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a30d7",
   "metadata": {},
   "source": [
    "### ANN vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdef24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: 560.7485\n",
      "95% CI: [-120.4406, 1241.9375]\n",
      "p-value: 0.10556369042204973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline)\n",
    "\n",
    "        ##################################################### ANN MODEL #################################################\n",
    "\n",
    "        model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "        # Define loss criterion\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Make a forward pass through the model to compute the outputs\n",
    "            outputs = model(X_train_inner_tensor)\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, y_train_inner_tensor)\n",
    "\n",
    "            # Make sure that the gradients are zero before you use backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "            loss.backward()\n",
    "            # Update the model parameters by making the optimizer take a gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_inner_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_inner_tensor)\n",
    "            loss_func_linear_ANN = val_loss.item()\n",
    "\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "\n",
    "        r_j = np.mean(loss_funcion_baseline - loss_func_linear_ANN)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f77d6",
   "metadata": {},
   "source": [
    "### Linear Reg vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "a65bcdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 111.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 350.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 343.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 327.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 333.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 333.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 328.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 288.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 336.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 326.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -1612.9596\n",
      "95% CI: [-2210.0660, -1015.8533]\n",
      "p-value: 5.443246472963441e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = Ridge(alpha = best_lambda_statistic_test, random_state=repeat_idx)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline)\n",
    "\n",
    "\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "        \n",
    "        r_j = np.mean(loss_func_linear_reg - loss_funcion_baseline)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c0fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
