{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8242ed63",
   "metadata": {},
   "source": [
    "# reg_part_B_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ba25",
   "metadata": {},
   "source": [
    "# Data import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c13ac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data_file=\"heart_failure_clinical_records_dataset\"\n",
    "\n",
    "data = pd.read_csv(f\"../../raw_data/{name_data_file}.csv\", na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac829f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0    75.0        0                       582         0                 20   \n",
       "1    55.0        0                      7861         0                 38   \n",
       "2    65.0        0                       146         0                 20   \n",
       "3    50.0        1                       111         0                 20   \n",
       "4    65.0        1                       160         1                 20   \n",
       "..    ...      ...                       ...       ...                ...   \n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      1  265000.00               1.9           130    1   \n",
       "1                      0  263358.03               1.1           136    1   \n",
       "2                      0  162000.00               1.3           129    1   \n",
       "3                      0  210000.00               1.9           137    1   \n",
       "4                      0  327000.00               2.7           116    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "294                    1  155000.00               1.1           143    1   \n",
       "295                    0  270000.00               1.2           139    0   \n",
       "296                    0  742000.00               0.8           138    0   \n",
       "297                    0  140000.00               1.4           140    1   \n",
       "298                    0  395000.00               1.6           136    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "0          0     4            1  \n",
       "1          0     6            1  \n",
       "2          1     7            1  \n",
       "3          0     7            1  \n",
       "4          0     8            1  \n",
       "..       ...   ...          ...  \n",
       "294        1   270            0  \n",
       "295        0   271            0  \n",
       "296        0   278            0  \n",
       "297        1   280            0  \n",
       "298        1   285            0  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598f101",
   "metadata": {},
   "source": [
    "# Cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5c41e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['time'])\n",
    "y = data['time']   # pandas Series\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "# X.shape, y.shape print shapes of X and y to undestand their dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3341fec",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "86e127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data based on training set\n",
    "\n",
    "def get_fold_data(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "# Tensor conversion\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "\n",
    "def get_model(input_dim, hidden_dim, output_dim):\n",
    "    ### BEGIN SOLUTION\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(in_features=input_dim, out_features=hidden_dim, bias=True),     # Input layer\n",
    "        torch.nn.Tanh(),                                                                # Activation function\n",
    "        torch.nn.Linear(in_features=hidden_dim, out_features=output_dim, bias=True),    # Output layer\n",
    "    )\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7b1ee",
   "metadata": {},
   "source": [
    "## 2 layer cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "\n",
    "outer_folds_k_1 = 10\n",
    "inner_folds_k_2 = 10\n",
    "random_state = 42\n",
    "\n",
    "# ANN parameters\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0.9\n",
    "hyperparameters_ANN = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "# Regularization parameters for linear regression\n",
    "lambdas__for_linear_regression = np.logspace(-4, 3, 30)[20:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 1 - Inner Fold 1\n",
      "Outer Fold 1 - Inner Fold 2\n",
      "Outer Fold 1 - Inner Fold 3\n",
      "Outer Fold 1 - Inner Fold 4\n",
      "Outer Fold 1 - Inner Fold 5\n",
      "Outer Fold 1 - Inner Fold 6\n",
      "Outer Fold 1 - Inner Fold 7\n",
      "Outer Fold 1 - Inner Fold 8\n",
      "Outer Fold 1 - Inner Fold 9\n",
      "Outer Fold 1 - Inner Fold 10\n",
      "{1: {0.5: {'train': [], 'test': [3667.5842468230458]}, 0.6: {'train': [], 'test': [3668.2842477397794]}, 0.8: {'train': [], 'test': [3669.6848694345617]}}, 2: {0.5: {'train': [], 'test': [3422.8098826729874]}, 0.6: {'train': [], 'test': [3422.6966262178835]}, 0.8: {'train': [], 'test': [3422.4739352011784]}}, 3: {0.5: {'train': [], 'test': [4633.762056353874]}, 0.6: {'train': [], 'test': [4633.390436563684]}, 0.8: {'train': [], 'test': [4632.649939033971]}}, 4: {0.5: {'train': [], 'test': [4539.151534299691]}, 0.6: {'train': [], 'test': [4538.394062447611]}, 0.8: {'train': [], 'test': [4536.883109144534]}}, 5: {0.5: {'train': [], 'test': [5460.699579348859]}, 0.6: {'train': [], 'test': [5459.741317282307]}, 0.8: {'train': [], 'test': [5457.834413519462]}}, 6: {0.5: {'train': [], 'test': [4408.03158271637]}, 0.6: {'train': [], 'test': [4407.994171273513]}, 0.8: {'train': [], 'test': [4407.9243636043875]}}, 7: {0.5: {'train': [], 'test': [3339.7074063021905]}, 0.6: {'train': [], 'test': [3339.478184706555]}, 0.8: {'train': [], 'test': [3339.023482175601]}}, 8: {0.5: {'train': [], 'test': [4384.46933346791]}, 0.6: {'train': [], 'test': [4384.53738920655]}, 0.8: {'train': [], 'test': [4384.676364024452]}}, 9: {0.5: {'train': [], 'test': [4908.509712219705]}, 0.6: {'train': [], 'test': [4908.525755619601]}, 0.8: {'train': [], 'test': [4908.5597631590845]}}, 10: {0.5: {'train': [], 'test': [4912.671044459451]}, 0.6: {'train': [], 'test': [4912.583823077358]}, 0.8: {'train': [], 'test': [4912.410664253496]}}}\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "For outer fold 1 Best λ (alpha): 0.8, Test MSE: 4685.796953396931\n",
      "For outer fold 1 Best hidden units: 4, Test MSE: 5544.0200\n",
      "For outer fold 1 Mean Inner fold MSE for Baseline: 6068.262610662071\n",
      "Outer Fold 2 - Inner Fold 1\n",
      "Outer Fold 2 - Inner Fold 2\n",
      "Outer Fold 2 - Inner Fold 3\n",
      "Outer Fold 2 - Inner Fold 4\n",
      "Outer Fold 2 - Inner Fold 5\n",
      "Outer Fold 2 - Inner Fold 6\n",
      "Outer Fold 2 - Inner Fold 7\n",
      "Outer Fold 2 - Inner Fold 8\n",
      "Outer Fold 2 - Inner Fold 9\n",
      "Outer Fold 2 - Inner Fold 10\n",
      "{1: {0.5: {'train': [], 'test': [3237.5668996831314]}, 0.6: {'train': [], 'test': [3238.336523505522]}, 0.8: {'train': [], 'test': [3239.875312616076]}}, 2: {0.5: {'train': [], 'test': [5886.048037772654]}, 0.6: {'train': [], 'test': [5884.665451413223]}, 0.8: {'train': [], 'test': [5881.90758817766]}}, 3: {0.5: {'train': [], 'test': [5536.804002130018]}, 0.6: {'train': [], 'test': [5535.813797771847]}, 0.8: {'train': [], 'test': [5533.840362387273]}}, 4: {0.5: {'train': [], 'test': [4349.7950652792915]}, 0.6: {'train': [], 'test': [4349.496633269818]}, 0.8: {'train': [], 'test': [4348.900179605971]}}, 5: {0.5: {'train': [], 'test': [3631.974837892735]}, 0.6: {'train': [], 'test': [3631.883243118078]}, 0.8: {'train': [], 'test': [3631.706990784083]}}, 6: {0.5: {'train': [], 'test': [3927.2759807237917]}, 0.6: {'train': [], 'test': [3927.6088095210225]}, 0.8: {'train': [], 'test': [3928.276278330953]}}, 7: {0.5: {'train': [], 'test': [3155.9389193928987]}, 0.6: {'train': [], 'test': [3155.843902560952]}, 0.8: {'train': [], 'test': [3155.657685789475]}}, 8: {0.5: {'train': [], 'test': [4733.185535212536]}, 0.6: {'train': [], 'test': [4732.846784080773]}, 0.8: {'train': [], 'test': [4732.1746702362525]}}, 9: {0.5: {'train': [], 'test': [6314.044080400044]}, 0.6: {'train': [], 'test': [6313.546213496664]}, 0.8: {'train': [], 'test': [6312.554219348751]}}, 10: {0.5: {'train': [], 'test': [4404.436062826995]}, 0.6: {'train': [], 'test': [4404.416697924191]}, 0.8: {'train': [], 'test': [4404.380845088564]}}}\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "For outer fold 2 Best λ (alpha): 0.8, Test MSE: 3958.8530753121013\n",
      "For outer fold 2 Best hidden units: 3, Test MSE: 5584.1436\n",
      "For outer fold 2 Mean Inner fold MSE for Baseline: 6064.930475785973\n",
      "Outer Fold 3 - Inner Fold 1\n",
      "Outer Fold 3 - Inner Fold 2\n",
      "Outer Fold 3 - Inner Fold 3\n",
      "Outer Fold 3 - Inner Fold 4\n",
      "Outer Fold 3 - Inner Fold 5\n",
      "Outer Fold 3 - Inner Fold 6\n",
      "Outer Fold 3 - Inner Fold 7\n",
      "Outer Fold 3 - Inner Fold 8\n",
      "Outer Fold 3 - Inner Fold 9\n",
      "Outer Fold 3 - Inner Fold 10\n",
      "{1: {0.5: {'train': [], 'test': [4302.483693419766]}, 0.6: {'train': [], 'test': [4302.555284421076]}, 0.8: {'train': [], 'test': [4302.701282933368]}}, 2: {0.5: {'train': [], 'test': [3607.717995609566]}, 0.6: {'train': [], 'test': [3606.891388145429]}, 0.8: {'train': [], 'test': [3605.2469705548547]}}, 3: {0.5: {'train': [], 'test': [4550.868602110051]}, 0.6: {'train': [], 'test': [4550.6622408212015]}, 0.8: {'train': [], 'test': [4550.25325435405]}}, 4: {0.5: {'train': [], 'test': [5268.826486665527]}, 0.6: {'train': [], 'test': [5267.535090220464]}, 0.8: {'train': [], 'test': [5264.958848881968]}}, 5: {0.5: {'train': [], 'test': [2948.392489110625]}, 0.6: {'train': [], 'test': [2949.287705443942]}, 0.8: {'train': [], 'test': [2951.0786881209733]}}, 6: {0.5: {'train': [], 'test': [5663.140880922421]}, 0.6: {'train': [], 'test': [5662.122103600596]}, 0.8: {'train': [], 'test': [5660.094547750084]}}, 7: {0.5: {'train': [], 'test': [3788.2852137488876]}, 0.6: {'train': [], 'test': [3788.0280575523393]}, 0.8: {'train': [], 'test': [3787.5162791268494]}}, 8: {0.5: {'train': [], 'test': [4027.4708624062096]}, 0.6: {'train': [], 'test': [4028.0600174509955]}, 0.8: {'train': [], 'test': [4029.2388650560383]}}, 9: {0.5: {'train': [], 'test': [4180.011618972194]}, 0.6: {'train': [], 'test': [4180.32711968616]}, 0.8: {'train': [], 'test': [4180.958899416613]}}, 10: {0.5: {'train': [], 'test': [6354.318731528754]}, 0.6: {'train': [], 'test': [6353.796481981228]}, 0.8: {'train': [], 'test': [6352.753980827803]}}}\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "For outer fold 3 Best λ (alpha): 0.8, Test MSE: 4513.7875187598165\n",
      "For outer fold 3 Best hidden units: 4, Test MSE: 6393.7231\n",
      "For outer fold 3 Mean Inner fold MSE for Baseline: 5976.123268870377\n",
      "Outer Fold 4 - Inner Fold 1\n",
      "Outer Fold 4 - Inner Fold 2\n",
      "Outer Fold 4 - Inner Fold 3\n",
      "Outer Fold 4 - Inner Fold 4\n",
      "Outer Fold 4 - Inner Fold 5\n",
      "Outer Fold 4 - Inner Fold 6\n",
      "Outer Fold 4 - Inner Fold 7\n",
      "Outer Fold 4 - Inner Fold 8\n",
      "Outer Fold 4 - Inner Fold 9\n",
      "Outer Fold 4 - Inner Fold 10\n",
      "{1: {0.5: {'train': [], 'test': [5646.702867798412]}, 0.6: {'train': [], 'test': [5646.275929493283]}, 0.8: {'train': [], 'test': [5645.426097632264]}}, 2: {0.5: {'train': [], 'test': [3315.8670800489344]}, 0.6: {'train': [], 'test': [3315.851251890352]}, 0.8: {'train': [], 'test': [3315.822395895694]}}, 3: {0.5: {'train': [], 'test': [3784.5755509792325]}, 0.6: {'train': [], 'test': [3784.3393682335113]}, 0.8: {'train': [], 'test': [3783.870321785978]}}, 4: {0.5: {'train': [], 'test': [4700.888302557477]}, 0.6: {'train': [], 'test': [4699.9430284468535]}, 0.8: {'train': [], 'test': [4698.056857491103]}}, 5: {0.5: {'train': [], 'test': [3950.153465067947]}, 0.6: {'train': [], 'test': [3950.4790810003815]}, 0.8: {'train': [], 'test': [3951.132570850835]}}, 6: {0.5: {'train': [], 'test': [4283.992110344688]}, 0.6: {'train': [], 'test': [4284.595085162055]}, 0.8: {'train': [], 'test': [4285.800780305969]}}, 7: {0.5: {'train': [], 'test': [3217.486883977218]}, 0.6: {'train': [], 'test': [3217.1909004852446]}, 0.8: {'train': [], 'test': [3216.6037065871583]}}, 8: {0.5: {'train': [], 'test': [5576.828911113569]}, 0.6: {'train': [], 'test': [5576.809371564413]}, 0.8: {'train': [], 'test': [5576.773717976099]}}, 9: {0.5: {'train': [], 'test': [5645.2029701322845]}, 0.6: {'train': [], 'test': [5645.115917547011]}, 0.8: {'train': [], 'test': [5644.94451108196]}}, 10: {0.5: {'train': [], 'test': [6290.396492678128]}, 0.6: {'train': [], 'test': [6289.676396394174]}, 0.8: {'train': [], 'test': [6288.24139070068]}}}\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
      "For outer fold 4 Best λ (alpha): 0.8, Test MSE: 2385.2446456164744\n",
      "For outer fold 4 Best hidden units: 3, Test MSE: 5103.5059\n",
      "For outer fold 4 Mean Inner fold MSE for Baseline: 6117.984225693168\n",
      "Outer Fold 5 - Inner Fold 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[244]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m optimizer.zero_grad()\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Update the model parameters by making the optimizer take a gradient descent step\u001b[39;00m\n\u001b[32m     74\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dtu02452/lib/python3.13/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dtu02452/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dtu02452/lib/python3.13/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lambdas__for_linear_regression=[0.5 ,0.6 ,0.8]\n",
    "\n",
    "CV_outer = KFold(n_splits=outer_folds_k_1, shuffle=True, random_state=random_state) \n",
    "\n",
    "fold_results = {}   # Outer fold dict (key: outer fold index)\n",
    "best_hyperparameters_per_fold = {}\n",
    "best_lambda_per_fold = {}\n",
    "outer_fold_index = 0\n",
    "\n",
    "for outer_train_idx, outer_test_idx in CV_outer.split(X):\n",
    "    outer_fold_index += 1\n",
    "    X_train_outer, X_test_outer, y_train_outer, y_test_outer = get_fold_data(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    CV_inner = KFold(n_splits=inner_folds_k_2, shuffle=True, random_state=random_state)\n",
    "    inner_mse_baseline = {}   # Inner fold dict (key: inner fold index)\n",
    "    inner_mse_ANN = {}\n",
    "    inner_mse_linear_regression = {}\n",
    "    inner_fold_index = 0\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in CV_inner.split(X_train_outer):\n",
    "        inner_fold_index += 1\n",
    "        print(f\"Outer Fold {outer_fold_index} - Inner Fold {inner_fold_index}\")\n",
    "\n",
    "        ############################# DATA Inner Fold ####################################\n",
    "        X_train_inner_norm, X_test_inner_norm, y_train_inner_norm, y_test_inner_norm = get_fold_data_normalized(X_train_outer, y_train_outer, inner_train_idx, inner_test_idx)\n",
    "\n",
    "        ############################# Linear Regression Inner Fold ####################################\n",
    "        \n",
    "        # Set up a dictionary to store the results for each lambda setting\n",
    "        results_inner_linear_regression = {lam: {'train': [], 'test': []} for lam in lambdas__for_linear_regression}\n",
    "\n",
    "        for lam in lambdas__for_linear_regression:\n",
    "\n",
    "            model = Ridge(alpha=lam, random_state=42)\n",
    "            model.fit(X_train_inner_norm, y_train_inner_norm)\n",
    "\n",
    "            y_test_pred_inner = model.predict(X_test_inner_norm)\n",
    "            mse_test = mean_squared_error(y_test_inner_norm, y_test_pred_inner)\n",
    "\n",
    "            results_inner_linear_regression[lam]['test'].append(mse_test)\n",
    "            inner_mse_linear_regression[inner_fold_index] = results_inner_linear_regression\n",
    "\n",
    "        ############################# ANN Inner Fold ########################################\n",
    "        X_train_inner_tensor, y_train_inner_tensor, X_test_inner_tensor, y_test_inner_tensor = torch_tensor_conversion(X_train_inner_norm, y_train_inner_norm, X_test_inner_norm, y_test_inner_norm) \n",
    "    \n",
    "        # Set up a dictionary to store the results for each hyperparameter setting\n",
    "        results_inner_ANN = {hidden_dim: {'train': [], 'test': []} for hidden_dim in hyperparameters_ANN}\n",
    "\n",
    "        for hidden_dim in hyperparameters_ANN:\n",
    "            # Define a model instance with a specific number of hidden units\n",
    "            model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "            # Define loss criterion\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "            optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "\n",
    "                # Set the model to training mode\n",
    "                model.train()\n",
    "\n",
    "                # Make a forward pass through the model to compute the outputs\n",
    "                outputs = model(X_train_inner_tensor)\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, y_train_inner_tensor)\n",
    "\n",
    "                # Make sure that the gradients are zero before you use backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "                loss.backward()\n",
    "                # Update the model parameters by making the optimizer take a gradient descent step\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Store the training loss for this epoch in the dictionary\n",
    "                #results_inner_ANN[hidden_dim]['train'].append(loss.item())\n",
    "\n",
    "            # Compute the final test loss on the test set\n",
    "            with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "                model.eval()\n",
    "                val_outputs = model(X_test_inner_tensor)\n",
    "                val_loss = criterion(val_outputs, y_test_inner_tensor)\n",
    "                results_inner_ANN[hidden_dim]['test'].append(val_loss.item())\n",
    "                #print(f'  Hidden units: {hidden_dim}, Validation set MSE: {val_loss.item():.4f}')\n",
    "                inner_mse_ANN[inner_fold_index] = results_inner_ANN \n",
    "\n",
    "        ############################# BASELINE Inner Fold ####################################\n",
    "        \n",
    "        y_train_mean = y_train_inner_norm.mean()\n",
    "        y_test_pred_inner = pd.Series(y_train_mean, index=y_test_inner_norm.index)\n",
    "        mse = mean_squared_error(y_test_inner_norm, y_test_pred_inner)\n",
    "        inner_mse_baseline[inner_fold_index] = mse   # Store by fold index\n",
    "\n",
    "\n",
    "    ############################ OUTER FOLD ##########################################################\n",
    "\n",
    "    ############################ Data ##########################################################\n",
    "\n",
    "    X_train_outer_norm, X_test_outer_norm, y_train_outer_norm, y_test_outer_norm = get_fold_data_normalized(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    X_train_outer_tensor, y_train_outer_tensor, X_test_outer_tensor, y_test_outer_tensor = torch_tensor_conversion(X_train_outer_norm, y_train_outer_norm, X_test_outer_norm, y_test_outer_norm)\n",
    "\n",
    "    ############################ Linear Regression Outer Fold ####################################\n",
    "\n",
    "    avg_mse_per_lambda = {}\n",
    "    for lam in lambdas__for_linear_regression:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_linear_regression.keys():\n",
    "            mse_values.append(inner_mse_linear_regression[inner_fold][lam]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_lambda[lam] = avg_mse\n",
    "    \n",
    "    best_lambda = min(avg_mse_per_lambda, key=avg_mse_per_lambda.get)\n",
    "    best_lambda_per_fold[outer_fold_index] = best_lambda\n",
    "\n",
    "    model = Ridge(alpha=best_lambda, random_state=42)\n",
    "    model.fit(X_train_outer_norm, y_train_outer_norm)\n",
    "    y_test_pred_outer = model.predict(X_test_outer_norm)\n",
    "    mse_test_outer = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "\n",
    "    ############################ ANN Outer Fold ####################################\n",
    "    # Find the best hyperparameter based on inner folds\n",
    "    avg_mse_per_hyperparam = {}\n",
    "    for hidden_dim in hyperparameters_ANN:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_ANN.keys():\n",
    "            mse_values.append(inner_mse_ANN[inner_fold][hidden_dim]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_hyperparam[hidden_dim] = avg_mse\n",
    "    \n",
    "    best_hyperparam = min(avg_mse_per_hyperparam, key=avg_mse_per_hyperparam.get)\n",
    "    best_hyperparameters_per_fold[outer_fold_index] = best_hyperparam\n",
    "\n",
    "    model = get_model(input_dim=input_dim, hidden_dim=best_hyperparam, output_dim=output_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "    model.train()\n",
    "    outputs = model(X_train_outer_tensor)\n",
    "    loss = criterion(outputs, y_train_outer_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_outer_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_outer_tensor)\n",
    "            print(f'For outer fold {outer_fold_index} Best hidden units: {best_hyperparam}, Test MSE: {val_loss.item():.4f}')\n",
    "    \n",
    "    ############################ BASELINE Outer Fold ###############################\n",
    "    inner_mse_mean = np.mean(list(inner_mse_baseline.values()))\n",
    "    fold_results[outer_fold_index] = inner_mse_baseline   # Store the whole dict per outer fold\n",
    "    print(f\"For outer fold {outer_fold_index} Mean Inner fold MSE for Baseline:\", inner_mse_mean)\n",
    "\n",
    "    ############################ Linear Regression Outer Fold ############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762a405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
