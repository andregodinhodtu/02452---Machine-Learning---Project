{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4599cd41",
   "metadata": {},
   "source": [
    "python 3.13.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242ed63",
   "metadata": {},
   "source": [
    "# reg_part_B_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ba25",
   "metadata": {},
   "source": [
    "# Data import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13ac8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dtu02452/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data_file=\"heart_failure_clinical_records_dataset\"\n",
    "\n",
    "data = pd.read_csv(f\"../../raw_data/{name_data_file}.csv\", na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac829f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0    75.0        0                       582         0                 20   \n",
       "1    55.0        0                      7861         0                 38   \n",
       "2    65.0        0                       146         0                 20   \n",
       "3    50.0        1                       111         0                 20   \n",
       "4    65.0        1                       160         1                 20   \n",
       "..    ...      ...                       ...       ...                ...   \n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                      1  265000.00               1.9           130    1   \n",
       "1                      0  263358.03               1.1           136    1   \n",
       "2                      0  162000.00               1.3           129    1   \n",
       "3                      0  210000.00               1.9           137    1   \n",
       "4                      0  327000.00               2.7           116    0   \n",
       "..                   ...        ...               ...           ...  ...   \n",
       "294                    1  155000.00               1.1           143    1   \n",
       "295                    0  270000.00               1.2           139    0   \n",
       "296                    0  742000.00               0.8           138    0   \n",
       "297                    0  140000.00               1.4           140    1   \n",
       "298                    0  395000.00               1.6           136    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "0          0     4            1  \n",
       "1          0     6            1  \n",
       "2          1     7            1  \n",
       "3          0     7            1  \n",
       "4          0     8            1  \n",
       "..       ...   ...          ...  \n",
       "294        1   270            0  \n",
       "295        0   271            0  \n",
       "296        0   278            0  \n",
       "297        1   280            0  \n",
       "298        1   285            0  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598f101",
   "metadata": {},
   "source": [
    "# Cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c41e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['time', \"DEATH_EVENT\"])\n",
    "y = data['time']   # pandas Series\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "# X.shape, y.shape print shapes of X and y to undestand their dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3341fec",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data based on training set\n",
    "\n",
    "def get_fold_data(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "# Tensor conversion\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "\n",
    "def get_model(input_dim, hidden_dim, output_dim):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(in_features=input_dim, out_features=hidden_dim, bias=True),     # Input layer\n",
    "        torch.nn.Tanh(),                                                                # Activation function\n",
    "        torch.nn.Linear(in_features=hidden_dim, out_features=output_dim, bias=True),    # Output layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7b1ee",
   "metadata": {},
   "source": [
    "## 2 layer cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105cc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "\n",
    "outer_folds_k_1 = 10\n",
    "inner_folds_k_2 = 10\n",
    "random_state = 42\n",
    "\n",
    "# ANN parameters\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0\n",
    "hyperparameters_ANN = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # hidden layer sizes to try\n",
    "\n",
    "\n",
    "# Regularization parameters for linear regression\n",
    "lambdas__for_linear_regression = np.logspace(-4, 3, 30)[23:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5b41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold 1 - Inner Fold 1\n",
      "Outer Fold 1 - Inner Fold 2\n",
      "Outer Fold 1 - Inner Fold 3\n",
      "Outer Fold 1 - Inner Fold 4\n",
      "Outer Fold 1 - Inner Fold 5\n",
      "Outer Fold 1 - Inner Fold 6\n",
      "Outer Fold 1 - Inner Fold 7\n",
      "Outer Fold 1 - Inner Fold 8\n",
      "Outer Fold 1 - Inner Fold 9\n",
      "Outer Fold 1 - Inner Fold 10\n",
      "For outer fold 1 Best λ (alpha): 188.73918221350996, Test MSE: 5157.651809924352\n",
      "For outer fold 1 Best hidden units: 1, Test MSE: 5830.5918\n",
      "For outer fold 1 Mean Inner fold MSE for Baseline: 5543.878799813896\n",
      "Outer Fold 2 - Inner Fold 1\n",
      "Outer Fold 2 - Inner Fold 2\n",
      "Outer Fold 2 - Inner Fold 3\n",
      "Outer Fold 2 - Inner Fold 4\n",
      "Outer Fold 2 - Inner Fold 5\n",
      "Outer Fold 2 - Inner Fold 6\n",
      "Outer Fold 2 - Inner Fold 7\n",
      "Outer Fold 2 - Inner Fold 8\n",
      "Outer Fold 2 - Inner Fold 9\n",
      "Outer Fold 2 - Inner Fold 10\n",
      "For outer fold 2 Best λ (alpha): 108.2636733874054, Test MSE: 5539.999850689881\n",
      "For outer fold 2 Best hidden units: 10, Test MSE: 5868.3828\n",
      "For outer fold 2 Mean Inner fold MSE for Baseline: 5599.172962415298\n",
      "Outer Fold 3 - Inner Fold 1\n",
      "Outer Fold 3 - Inner Fold 2\n",
      "Outer Fold 3 - Inner Fold 3\n",
      "Outer Fold 3 - Inner Fold 4\n",
      "Outer Fold 3 - Inner Fold 5\n",
      "Outer Fold 3 - Inner Fold 6\n",
      "Outer Fold 3 - Inner Fold 7\n",
      "Outer Fold 3 - Inner Fold 8\n",
      "Outer Fold 3 - Inner Fold 9\n",
      "Outer Fold 3 - Inner Fold 10\n",
      "For outer fold 3 Best λ (alpha): 188.73918221350996, Test MSE: 5635.661464402289\n",
      "For outer fold 3 Best hidden units: 1, Test MSE: 5872.5991\n",
      "For outer fold 3 Mean Inner fold MSE for Baseline: 6384.788365740292\n",
      "Outer Fold 4 - Inner Fold 1\n",
      "Outer Fold 4 - Inner Fold 2\n",
      "Outer Fold 4 - Inner Fold 3\n",
      "Outer Fold 4 - Inner Fold 4\n",
      "Outer Fold 4 - Inner Fold 5\n",
      "Outer Fold 4 - Inner Fold 6\n",
      "Outer Fold 4 - Inner Fold 7\n",
      "Outer Fold 4 - Inner Fold 8\n",
      "Outer Fold 4 - Inner Fold 9\n",
      "Outer Fold 4 - Inner Fold 10\n",
      "For outer fold 4 Best λ (alpha): 188.73918221350996, Test MSE: 3895.681958702486\n",
      "For outer fold 4 Best hidden units: 1, Test MSE: 3992.0088\n",
      "For outer fold 4 Mean Inner fold MSE for Baseline: 5103.847463873265\n",
      "Outer Fold 5 - Inner Fold 1\n",
      "Outer Fold 5 - Inner Fold 2\n",
      "Outer Fold 5 - Inner Fold 3\n",
      "Outer Fold 5 - Inner Fold 4\n",
      "Outer Fold 5 - Inner Fold 5\n",
      "Outer Fold 5 - Inner Fold 6\n",
      "Outer Fold 5 - Inner Fold 7\n",
      "Outer Fold 5 - Inner Fold 8\n",
      "Outer Fold 5 - Inner Fold 9\n",
      "Outer Fold 5 - Inner Fold 10\n",
      "For outer fold 5 Best λ (alpha): 188.73918221350996, Test MSE: 4070.970269410557\n",
      "For outer fold 5 Best hidden units: 2, Test MSE: 5254.2246\n",
      "For outer fold 5 Mean Inner fold MSE for Baseline: 4707.1240511693695\n",
      "Outer Fold 6 - Inner Fold 1\n",
      "Outer Fold 6 - Inner Fold 2\n",
      "Outer Fold 6 - Inner Fold 3\n",
      "Outer Fold 6 - Inner Fold 4\n",
      "Outer Fold 6 - Inner Fold 5\n",
      "Outer Fold 6 - Inner Fold 6\n",
      "Outer Fold 6 - Inner Fold 7\n",
      "Outer Fold 6 - Inner Fold 8\n",
      "Outer Fold 6 - Inner Fold 9\n",
      "Outer Fold 6 - Inner Fold 10\n",
      "For outer fold 6 Best λ (alpha): 108.2636733874054, Test MSE: 6070.225766168865\n",
      "For outer fold 6 Best hidden units: 5, Test MSE: 6002.2529\n",
      "For outer fold 6 Mean Inner fold MSE for Baseline: 6811.592483980782\n",
      "Outer Fold 7 - Inner Fold 1\n",
      "Outer Fold 7 - Inner Fold 2\n",
      "Outer Fold 7 - Inner Fold 3\n",
      "Outer Fold 7 - Inner Fold 4\n",
      "Outer Fold 7 - Inner Fold 5\n",
      "Outer Fold 7 - Inner Fold 6\n",
      "Outer Fold 7 - Inner Fold 7\n",
      "Outer Fold 7 - Inner Fold 8\n",
      "Outer Fold 7 - Inner Fold 9\n",
      "Outer Fold 7 - Inner Fold 10\n",
      "For outer fold 7 Best λ (alpha): 188.73918221350996, Test MSE: 6354.279279862539\n",
      "For outer fold 7 Best hidden units: 8, Test MSE: 6825.5386\n",
      "For outer fold 7 Mean Inner fold MSE for Baseline: 6991.245497344335\n",
      "Outer Fold 8 - Inner Fold 1\n",
      "Outer Fold 8 - Inner Fold 2\n",
      "Outer Fold 8 - Inner Fold 3\n",
      "Outer Fold 8 - Inner Fold 4\n",
      "Outer Fold 8 - Inner Fold 5\n",
      "Outer Fold 8 - Inner Fold 6\n",
      "Outer Fold 8 - Inner Fold 7\n",
      "Outer Fold 8 - Inner Fold 8\n",
      "Outer Fold 8 - Inner Fold 9\n",
      "Outer Fold 8 - Inner Fold 10\n",
      "For outer fold 8 Best λ (alpha): 108.2636733874054, Test MSE: 8347.406782127558\n",
      "For outer fold 8 Best hidden units: 7, Test MSE: 7928.2559\n",
      "For outer fold 8 Mean Inner fold MSE for Baseline: 7346.2819962871345\n",
      "Outer Fold 9 - Inner Fold 1\n",
      "Outer Fold 9 - Inner Fold 2\n",
      "Outer Fold 9 - Inner Fold 3\n",
      "Outer Fold 9 - Inner Fold 4\n",
      "Outer Fold 9 - Inner Fold 5\n",
      "Outer Fold 9 - Inner Fold 6\n",
      "Outer Fold 9 - Inner Fold 7\n",
      "Outer Fold 9 - Inner Fold 8\n",
      "Outer Fold 9 - Inner Fold 9\n",
      "Outer Fold 9 - Inner Fold 10\n",
      "For outer fold 9 Best λ (alpha): 188.73918221350996, Test MSE: 6645.9438827069425\n",
      "For outer fold 9 Best hidden units: 1, Test MSE: 6153.0737\n",
      "For outer fold 9 Mean Inner fold MSE for Baseline: 5970.658637940327\n",
      "Outer Fold 10 - Inner Fold 1\n",
      "Outer Fold 10 - Inner Fold 2\n",
      "Outer Fold 10 - Inner Fold 3\n",
      "Outer Fold 10 - Inner Fold 4\n",
      "Outer Fold 10 - Inner Fold 5\n",
      "Outer Fold 10 - Inner Fold 6\n",
      "Outer Fold 10 - Inner Fold 7\n",
      "Outer Fold 10 - Inner Fold 8\n",
      "Outer Fold 10 - Inner Fold 9\n",
      "Outer Fold 10 - Inner Fold 10\n",
      "For outer fold 10 Best λ (alpha): 108.2636733874054, Test MSE: 5220.648247396514\n",
      "For outer fold 10 Best hidden units: 1, Test MSE: 5423.5996\n",
      "For outer fold 10 Mean Inner fold MSE for Baseline: 5815.648143891019\n"
     ]
    }
   ],
   "source": [
    "CV_outer = KFold(n_splits=outer_folds_k_1, shuffle=True, random_state=random_state) \n",
    "\n",
    "baseline_per_fold = {}   # Outer fold dict (key: outer fold index)\n",
    "best_hyperparameters_per_fold = {}\n",
    "best_lambda_per_fold = {}\n",
    "fold_results = {}\n",
    "outer_fold_index = 0\n",
    "\n",
    "for outer_train_idx, outer_test_idx in CV_outer.split(X):\n",
    "    outer_fold_index += 1\n",
    "    X_train_outer, X_test_outer, y_train_outer, y_test_outer = get_fold_data(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    CV_inner = KFold(n_splits=inner_folds_k_2, shuffle=True, random_state=random_state)\n",
    "    inner_mse_ANN = {}\n",
    "    inner_mse_linear_regression = {}\n",
    "    inner_fold_index = 0\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in CV_inner.split(X_train_outer):\n",
    "        inner_fold_index += 1\n",
    "        print(f\"Outer Fold {outer_fold_index} - Inner Fold {inner_fold_index}\")\n",
    "\n",
    "        ############################# DATA Inner Fold ####################################\n",
    "        X_train_inner_norm, X_test_inner_norm, y_train_inner_norm, y_test_inner_norm = get_fold_data_normalized(X_train_outer, y_train_outer, inner_train_idx, inner_test_idx)\n",
    "\n",
    "        ############################# Linear Regression Inner Fold ####################################\n",
    "        \n",
    "        # Set up a dictionary to store the results for each lambda setting\n",
    "        results_inner_linear_regression = {lam: {'train': [], 'test': []} for lam in lambdas__for_linear_regression}\n",
    "\n",
    "        for lam in lambdas__for_linear_regression:\n",
    "\n",
    "            model = Ridge(alpha=lam, random_state=42)\n",
    "            model.fit(X_train_inner_norm, y_train_inner_norm)\n",
    "\n",
    "            y_test_pred_inner = model.predict(X_test_inner_norm)\n",
    "            mse_test = mean_squared_error(y_test_inner_norm, y_test_pred_inner)\n",
    "\n",
    "            results_inner_linear_regression[lam]['test'].append(mse_test)\n",
    "            inner_mse_linear_regression[inner_fold_index] = results_inner_linear_regression\n",
    "\n",
    "        ############################# ANN Inner Fold ########################################\n",
    "        X_train_inner_tensor, y_train_inner_tensor, X_test_inner_tensor, y_test_inner_tensor = torch_tensor_conversion(X_train_inner_norm, y_train_inner_norm, X_test_inner_norm, y_test_inner_norm) \n",
    "    \n",
    "        # Set up a dictionary to store the results for each hyperparameter setting\n",
    "        results_inner_ANN = {hidden_dim: {'train': [], 'test': []} for hidden_dim in hyperparameters_ANN}\n",
    "\n",
    "        for hidden_dim in hyperparameters_ANN:\n",
    "            # Define a model instance with a specific number of hidden units\n",
    "            model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "            # Define loss criterion\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "            optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "\n",
    "                # Set the model to training mode\n",
    "                model.train()\n",
    "\n",
    "                # Make a forward pass through the model to compute the outputs\n",
    "                outputs = model(X_train_inner_tensor)\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, y_train_inner_tensor)\n",
    "\n",
    "                # Make sure that the gradients are zero before you use backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "                loss.backward()\n",
    "                # Update the model parameters by making the optimizer take a gradient descent step\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Store the training loss for this epoch in the dictionary\n",
    "                #results_inner_ANN[hidden_dim]['train'].append(loss.item())\n",
    "\n",
    "            # Compute the final test loss on the test set\n",
    "            with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "                model.eval()\n",
    "                val_outputs = model(X_test_inner_tensor)\n",
    "                val_loss = criterion(val_outputs, y_test_inner_tensor)\n",
    "                results_inner_ANN[hidden_dim]['test'].append(val_loss.item())\n",
    "                #print(f'  Hidden units: {hidden_dim}, Validation set MSE: {val_loss.item():.4f}')\n",
    "                inner_mse_ANN[inner_fold_index] = results_inner_ANN \n",
    "\n",
    "        ############################# BASELINE Inner Fold ####################################\n",
    "\n",
    "        #----\n",
    "\n",
    "    ############################ OUTER FOLD ##########################################################\n",
    "\n",
    "    ############################ Data ##########################################################\n",
    "\n",
    "    X_train_outer_norm, X_test_outer_norm, y_train_outer_norm, y_test_outer_norm = get_fold_data_normalized(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    X_train_outer_tensor, y_train_outer_tensor, X_test_outer_tensor, y_test_outer_tensor = torch_tensor_conversion(X_train_outer_norm, y_train_outer_norm, X_test_outer_norm, y_test_outer_norm)\n",
    "\n",
    "    ############################ Linear Regression Outer Fold ####################################\n",
    "\n",
    "    avg_mse_per_lambda = {}\n",
    "    for lam in lambdas__for_linear_regression:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_linear_regression.keys():\n",
    "            mse_values.append(inner_mse_linear_regression[inner_fold][lam]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_lambda[lam] = avg_mse\n",
    "    \n",
    "    best_lambda = min(avg_mse_per_lambda, key=avg_mse_per_lambda.get)\n",
    "    best_lambda_per_fold[outer_fold_index] = best_lambda\n",
    "\n",
    "    model = Ridge(alpha=best_lambda, random_state=42)\n",
    "    model.fit(X_train_outer_norm, y_train_outer_norm)\n",
    "    y_test_pred_outer = model.predict(X_test_outer_norm)\n",
    "    mse_test_outer = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "    print(f\"For outer fold {outer_fold_index} Best λ (alpha): {best_lambda}, Test MSE: {mse_test_outer}\")\n",
    "\n",
    "    ############################ ANN Outer Fold ####################################\n",
    "    # Find the best hyperparameter based on inner folds\n",
    "    avg_mse_per_hyperparam = {}\n",
    "    for hidden_dim in hyperparameters_ANN:\n",
    "        mse_values = []\n",
    "        for inner_fold in inner_mse_ANN.keys():\n",
    "            mse_values.append(inner_mse_ANN[inner_fold][hidden_dim]['test'][0])  # We only have one value of test per fold \n",
    "        avg_mse = np.mean(mse_values)\n",
    "        avg_mse_per_hyperparam[hidden_dim] = avg_mse\n",
    "        \n",
    "    \n",
    "    best_hyperparam = min(avg_mse_per_hyperparam, key=avg_mse_per_hyperparam.get)\n",
    "    best_hyperparameters_per_fold[outer_fold_index] = best_hyperparam\n",
    "\n",
    "\n",
    "    model = get_model(input_dim=input_dim, hidden_dim=best_hyperparam, output_dim=output_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        outputs = model(X_train_outer_tensor)\n",
    "        loss = criterion(outputs, y_train_outer_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad(): # No need to compute gradients for the validation set\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_outer_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_outer_tensor)\n",
    "            print(f'For outer fold {outer_fold_index} Best hidden units: {best_hyperparam}, Test MSE: {val_loss.item():.4f}')\n",
    "    \n",
    "    ############################ BASELINE Outer Fold ###############################\n",
    "\n",
    "    y_train_mean = y_train_outer_norm.mean()\n",
    "    y_test_pred_outer = pd.Series(y_train_mean, index=y_test_outer_norm.index)\n",
    "    outer_mse_baseline = mean_squared_error(y_test_outer_norm, y_test_pred_outer)\n",
    "    baseline_per_fold[outer_fold_index] = outer_mse_baseline \n",
    "    print(f\"For outer fold {outer_fold_index} Mean Inner fold MSE for Baseline:\", outer_mse_baseline)\n",
    "\n",
    "    ############################# STORE RESULTS ####################################\n",
    "\n",
    "    fold_results[outer_fold_index] = {\n",
    "        \"linear_regression_best_lambda\": best_lambda,\n",
    "        \"linear_regression_mse\": mse_test_outer,\n",
    "        \"ANN_best_hidden_units\": best_hyperparam,\n",
    "        \"ANN_mse\": val_loss.item(),\n",
    "        \"baseline_outer_mse\": outer_mse_baseline\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e50922",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3f436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_best_parameters(dict_parameters_for_each_outer_fold):\n",
    "    count_parameter_dict = {}\n",
    "    for outer_fold_index in dict_parameters_for_each_outer_fold.keys():\n",
    "        if dict_parameters_for_each_outer_fold.get(outer_fold_index) not in count_parameter_dict.keys() :\n",
    "            count_parameter_dict[dict_parameters_for_each_outer_fold.get(outer_fold_index)] = 1\n",
    "\n",
    "        else:\n",
    "            count_parameter_dict[dict_parameters_for_each_outer_fold.get(outer_fold_index)] += 1\n",
    "\n",
    "    return count_parameter_dict\n",
    "\n",
    "def best_parameter(count_parameter_dict):\n",
    "    best_param = max(count_parameter_dict, key=count_parameter_dict.get)\n",
    "    return best_param\n",
    "\n",
    "best_lambda = best_parameter(count_best_parameters(best_lambda_per_fold))\n",
    "best_hyperparameter = best_parameter(count_best_parameters(best_hyperparameters_per_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af694643",
   "metadata": {},
   "source": [
    "### learning_rate = 0.001, momentum = 0, n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6fbc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "learning_rate = 0.001, momentum = 0, n_epochs = 1000\n",
      "Mean ANN MSE across outer folds: 5915.052783203125\n",
      "Mean difference between baseline and ANN MSE across outer folds: 112.37105704244668\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_regression_best_lambda</th>\n",
       "      <th>linear_regression_mse</th>\n",
       "      <th>ANN_best_hidden_units</th>\n",
       "      <th>ANN_mse</th>\n",
       "      <th>baseline_outer_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5157.651810</td>\n",
       "      <td>1</td>\n",
       "      <td>5830.591797</td>\n",
       "      <td>5543.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5539.999851</td>\n",
       "      <td>10</td>\n",
       "      <td>5868.382812</td>\n",
       "      <td>5599.172962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5635.661464</td>\n",
       "      <td>1</td>\n",
       "      <td>5872.599121</td>\n",
       "      <td>6384.788366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>3895.681959</td>\n",
       "      <td>1</td>\n",
       "      <td>3992.008789</td>\n",
       "      <td>5103.847464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>4070.970269</td>\n",
       "      <td>2</td>\n",
       "      <td>5254.224609</td>\n",
       "      <td>4707.124051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>6070.225766</td>\n",
       "      <td>5</td>\n",
       "      <td>6002.252930</td>\n",
       "      <td>6811.592484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6354.279280</td>\n",
       "      <td>8</td>\n",
       "      <td>6825.538574</td>\n",
       "      <td>6991.245497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>8347.406782</td>\n",
       "      <td>7</td>\n",
       "      <td>7928.255859</td>\n",
       "      <td>7346.281996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6645.943883</td>\n",
       "      <td>1</td>\n",
       "      <td>6153.073730</td>\n",
       "      <td>5970.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5220.648247</td>\n",
       "      <td>1</td>\n",
       "      <td>5423.599609</td>\n",
       "      <td>5815.648144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_regression_best_lambda  linear_regression_mse  \\\n",
       "1                      188.739182            5157.651810   \n",
       "2                      108.263673            5539.999851   \n",
       "3                      188.739182            5635.661464   \n",
       "4                      188.739182            3895.681959   \n",
       "5                      188.739182            4070.970269   \n",
       "6                      108.263673            6070.225766   \n",
       "7                      188.739182            6354.279280   \n",
       "8                      108.263673            8347.406782   \n",
       "9                      188.739182            6645.943883   \n",
       "10                     108.263673            5220.648247   \n",
       "\n",
       "    ANN_best_hidden_units      ANN_mse  baseline_outer_mse  \n",
       "1                       1  5830.591797         5543.878800  \n",
       "2                      10  5868.382812         5599.172962  \n",
       "3                       1  5872.599121         6384.788366  \n",
       "4                       1  3992.008789         5103.847464  \n",
       "5                       2  5254.224609         4707.124051  \n",
       "6                       5  6002.252930         6811.592484  \n",
       "7                       8  6825.538574         6991.245497  \n",
       "8                       7  7928.255859         7346.281996  \n",
       "9                       1  6153.073730         5970.658638  \n",
       "10                      1  5423.599609         5815.648144  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(f\"learning_rate = {lr}, momentum = {momentum}, n_epochs = {n_epochs}\")\n",
    "mean_ANN_mse = outer_results_df['ANN_mse'].mean()\n",
    "difference_ANN_mse_baseline_mse = (outer_results_df['baseline_outer_mse'] - outer_results_df['ANN_mse']).mean()\n",
    "print(f\"Mean ANN MSE across outer folds: {mean_ANN_mse}\")\n",
    "print(f\"Mean difference between baseline and ANN MSE across outer folds: {difference_ANN_mse_baseline_mse}\")\n",
    "outer_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a4f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ (alpha) for Linear Regression across all outer folds: 188.73918221350996\n",
      "Best hidden units for ANN across all outer folds: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best λ (alpha) for Linear Regression across all outer folds:\", best_lambda)\n",
    "print(\"Best hidden units for ANN across all outer folds:\", best_hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef89fdd",
   "metadata": {},
   "source": [
    "### learning_rate = 0.001, momentum = 0.5, n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6664de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "learning_rate = 0.001, momentum = 0.5, n_epochs = 1000\n",
      "Mean ANN MSE across outer folds: 6160.3056640625\n",
      "Mean difference between baseline and ANN MSE across outer folds: -132.88182381692832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_regression_best_lambda</th>\n",
       "      <th>linear_regression_mse</th>\n",
       "      <th>ANN_best_hidden_units</th>\n",
       "      <th>ANN_mse</th>\n",
       "      <th>baseline_outer_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5157.651810</td>\n",
       "      <td>3</td>\n",
       "      <td>5940.164062</td>\n",
       "      <td>5543.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5539.999851</td>\n",
       "      <td>5</td>\n",
       "      <td>6087.937012</td>\n",
       "      <td>5599.172962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5635.661464</td>\n",
       "      <td>2</td>\n",
       "      <td>5815.179199</td>\n",
       "      <td>6384.788366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>3895.681959</td>\n",
       "      <td>1</td>\n",
       "      <td>3975.016602</td>\n",
       "      <td>5103.847464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>4070.970269</td>\n",
       "      <td>1</td>\n",
       "      <td>5228.653320</td>\n",
       "      <td>4707.124051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>6070.225766</td>\n",
       "      <td>3</td>\n",
       "      <td>6504.273926</td>\n",
       "      <td>6811.592484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6354.279280</td>\n",
       "      <td>4</td>\n",
       "      <td>6552.671387</td>\n",
       "      <td>6991.245497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>8347.406782</td>\n",
       "      <td>1</td>\n",
       "      <td>9074.388672</td>\n",
       "      <td>7346.281996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6645.943883</td>\n",
       "      <td>1</td>\n",
       "      <td>6105.773438</td>\n",
       "      <td>5970.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5220.648247</td>\n",
       "      <td>3</td>\n",
       "      <td>6318.999023</td>\n",
       "      <td>5815.648144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_regression_best_lambda  linear_regression_mse  \\\n",
       "1                      188.739182            5157.651810   \n",
       "2                      108.263673            5539.999851   \n",
       "3                      188.739182            5635.661464   \n",
       "4                      188.739182            3895.681959   \n",
       "5                      188.739182            4070.970269   \n",
       "6                      108.263673            6070.225766   \n",
       "7                      188.739182            6354.279280   \n",
       "8                      108.263673            8347.406782   \n",
       "9                      188.739182            6645.943883   \n",
       "10                     108.263673            5220.648247   \n",
       "\n",
       "    ANN_best_hidden_units      ANN_mse  baseline_outer_mse  \n",
       "1                       3  5940.164062         5543.878800  \n",
       "2                       5  6087.937012         5599.172962  \n",
       "3                       2  5815.179199         6384.788366  \n",
       "4                       1  3975.016602         5103.847464  \n",
       "5                       1  5228.653320         4707.124051  \n",
       "6                       3  6504.273926         6811.592484  \n",
       "7                       4  6552.671387         6991.245497  \n",
       "8                       1  9074.388672         7346.281996  \n",
       "9                       1  6105.773438         5970.658638  \n",
       "10                      3  6318.999023         5815.648144  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(f\"learning_rate = {lr}, momentum = {momentum}, n_epochs = {n_epochs}\")\n",
    "mean_ANN_mse = outer_results_df['ANN_mse'].mean()\n",
    "difference_ANN_mse_baseline_mse = (outer_results_df['baseline_outer_mse'] - outer_results_df['ANN_mse']).mean()\n",
    "print(f\"Mean ANN MSE across outer folds: {mean_ANN_mse}\")\n",
    "print(f\"Mean difference between baseline and ANN MSE across outer folds: {difference_ANN_mse_baseline_mse}\")\n",
    "outer_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f30da678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ (alpha) for Linear Regression across all outer folds: 188.73918221350996\n",
      "Best hidden units for ANN across all outer folds: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best λ (alpha) for Linear Regression across all outer folds:\", best_lambda)\n",
    "print(\"Best hidden units for ANN across all outer folds:\", best_hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74979e46",
   "metadata": {},
   "source": [
    "### learning_rate = 0.001, momentum = 0.9, n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "360d4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "learning_rate = 0.001, momentum = 0.9, n_epochs = 1000\n",
      "Mean ANN MSE across outer folds: 6191.557177734375\n",
      "Mean difference between baseline and ANN MSE across outer folds: -164.1333374888033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_regression_best_lambda</th>\n",
       "      <th>linear_regression_mse</th>\n",
       "      <th>ANN_best_hidden_units</th>\n",
       "      <th>ANN_mse</th>\n",
       "      <th>baseline_outer_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5157.651810</td>\n",
       "      <td>2</td>\n",
       "      <td>6731.850098</td>\n",
       "      <td>5543.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5539.999851</td>\n",
       "      <td>2</td>\n",
       "      <td>6945.989258</td>\n",
       "      <td>5599.172962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5635.661464</td>\n",
       "      <td>1</td>\n",
       "      <td>5956.526855</td>\n",
       "      <td>6384.788366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>3895.681959</td>\n",
       "      <td>1</td>\n",
       "      <td>4013.535156</td>\n",
       "      <td>5103.847464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>4070.970269</td>\n",
       "      <td>1</td>\n",
       "      <td>5132.639160</td>\n",
       "      <td>4707.124051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>6070.225766</td>\n",
       "      <td>3</td>\n",
       "      <td>6418.666504</td>\n",
       "      <td>6811.592484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6354.279280</td>\n",
       "      <td>1</td>\n",
       "      <td>6034.097168</td>\n",
       "      <td>6991.245497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>8347.406782</td>\n",
       "      <td>2</td>\n",
       "      <td>8870.155273</td>\n",
       "      <td>7346.281996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6645.943883</td>\n",
       "      <td>1</td>\n",
       "      <td>6152.852051</td>\n",
       "      <td>5970.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5220.648247</td>\n",
       "      <td>1</td>\n",
       "      <td>5659.260254</td>\n",
       "      <td>5815.648144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_regression_best_lambda  linear_regression_mse  \\\n",
       "1                      188.739182            5157.651810   \n",
       "2                      108.263673            5539.999851   \n",
       "3                      188.739182            5635.661464   \n",
       "4                      188.739182            3895.681959   \n",
       "5                      188.739182            4070.970269   \n",
       "6                      108.263673            6070.225766   \n",
       "7                      188.739182            6354.279280   \n",
       "8                      108.263673            8347.406782   \n",
       "9                      188.739182            6645.943883   \n",
       "10                     108.263673            5220.648247   \n",
       "\n",
       "    ANN_best_hidden_units      ANN_mse  baseline_outer_mse  \n",
       "1                       2  6731.850098         5543.878800  \n",
       "2                       2  6945.989258         5599.172962  \n",
       "3                       1  5956.526855         6384.788366  \n",
       "4                       1  4013.535156         5103.847464  \n",
       "5                       1  5132.639160         4707.124051  \n",
       "6                       3  6418.666504         6811.592484  \n",
       "7                       1  6034.097168         6991.245497  \n",
       "8                       2  8870.155273         7346.281996  \n",
       "9                       1  6152.852051         5970.658638  \n",
       "10                      1  5659.260254         5815.648144  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(f\"learning_rate = {lr}, momentum = {momentum}, n_epochs = {n_epochs}\")\n",
    "mean_ANN_mse = outer_results_df['ANN_mse'].mean()\n",
    "difference_ANN_mse_baseline_mse = (outer_results_df['baseline_outer_mse'] - outer_results_df['ANN_mse']).mean()\n",
    "print(f\"Mean ANN MSE across outer folds: {mean_ANN_mse}\")\n",
    "print(f\"Mean difference between baseline and ANN MSE across outer folds: {difference_ANN_mse_baseline_mse}\")\n",
    "outer_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "15da65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ (alpha) for Linear Regression across all outer folds: 108.2636733874054\n",
      "Best hidden units for ANN across all outer folds: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best λ (alpha) for Linear Regression across all outer folds:\", best_lambda)\n",
    "print(\"Best hidden units for ANN across all outer folds:\", best_hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a6cbb",
   "metadata": {},
   "source": [
    "### learning_rate = 0.001, momentum = 0.9, n_epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30c99873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "learning_rate = 0.001, momentum = 0.9, n_epochs = 10000\n",
      "Mean ANN MSE across outer folds: 6448.2427734375\n",
      "Mean difference between baseline and ANN MSE across outer folds: -420.8189331919283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_regression_best_lambda</th>\n",
       "      <th>linear_regression_mse</th>\n",
       "      <th>ANN_best_hidden_units</th>\n",
       "      <th>ANN_mse</th>\n",
       "      <th>baseline_outer_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5157.651810</td>\n",
       "      <td>1</td>\n",
       "      <td>6556.806152</td>\n",
       "      <td>5543.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5539.999851</td>\n",
       "      <td>4</td>\n",
       "      <td>5517.922852</td>\n",
       "      <td>5599.172962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>5635.661464</td>\n",
       "      <td>1</td>\n",
       "      <td>6256.265137</td>\n",
       "      <td>6384.788366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>3895.681959</td>\n",
       "      <td>1</td>\n",
       "      <td>3596.608887</td>\n",
       "      <td>5103.847464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>4070.970269</td>\n",
       "      <td>4</td>\n",
       "      <td>5874.966309</td>\n",
       "      <td>4707.124051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>6070.225766</td>\n",
       "      <td>3</td>\n",
       "      <td>6468.523926</td>\n",
       "      <td>6811.592484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6354.279280</td>\n",
       "      <td>1</td>\n",
       "      <td>7647.459473</td>\n",
       "      <td>6991.245497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>8347.406782</td>\n",
       "      <td>2</td>\n",
       "      <td>9454.005859</td>\n",
       "      <td>7346.281996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>188.739182</td>\n",
       "      <td>6645.943883</td>\n",
       "      <td>3</td>\n",
       "      <td>7646.244629</td>\n",
       "      <td>5970.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.263673</td>\n",
       "      <td>5220.648247</td>\n",
       "      <td>1</td>\n",
       "      <td>5463.624512</td>\n",
       "      <td>5815.648144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linear_regression_best_lambda  linear_regression_mse  \\\n",
       "1                      188.739182            5157.651810   \n",
       "2                      108.263673            5539.999851   \n",
       "3                      188.739182            5635.661464   \n",
       "4                      188.739182            3895.681959   \n",
       "5                      188.739182            4070.970269   \n",
       "6                      108.263673            6070.225766   \n",
       "7                      188.739182            6354.279280   \n",
       "8                      108.263673            8347.406782   \n",
       "9                      188.739182            6645.943883   \n",
       "10                     108.263673            5220.648247   \n",
       "\n",
       "    ANN_best_hidden_units      ANN_mse  baseline_outer_mse  \n",
       "1                       1  6556.806152         5543.878800  \n",
       "2                       4  5517.922852         5599.172962  \n",
       "3                       1  6256.265137         6384.788366  \n",
       "4                       1  3596.608887         5103.847464  \n",
       "5                       4  5874.966309         4707.124051  \n",
       "6                       3  6468.523926         6811.592484  \n",
       "7                       1  7647.459473         6991.245497  \n",
       "8                       2  9454.005859         7346.281996  \n",
       "9                       3  7646.244629         5970.658638  \n",
       "10                      1  5463.624512         5815.648144  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(f\"learning_rate = {lr}, momentum = {momentum}, n_epochs = {n_epochs}\")\n",
    "mean_ANN_mse = outer_results_df['ANN_mse'].mean()\n",
    "difference_ANN_mse_baseline_mse = (outer_results_df['baseline_outer_mse'] - outer_results_df['ANN_mse']).mean()\n",
    "print(f\"Mean ANN MSE across outer folds: {mean_ANN_mse}\")\n",
    "print(f\"Mean difference between baseline and ANN MSE across outer folds: {difference_ANN_mse_baseline_mse}\")\n",
    "outer_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ (alpha) for Linear Regression across all outer folds: 188.73918221350996\n",
      "Best hidden units for ANN across all outer folds: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best λ (alpha) for Linear Regression across all outer folds:\", best_lambda)\n",
    "print(\"Best hidden units for ANN across all outer folds:\", best_hyperparameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b20091",
   "metadata": {},
   "source": [
    "# Statistical Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ab9e3",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d2aa45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_ttest(r, rho, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform a correlated t-test to compare two models under Setup II.\n",
    "\n",
    "    Parameters:\n",
    "    - r (array-like): Array of performance differences across folds (e.g. r_j = error_A - error_B)\n",
    "    - rho (float): Correlation coefficient between folds (typically 1/K for K-fold CV)\n",
    "    - alpha (float, optional): Significance level (default: 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - p (float): p-value of the test\n",
    "    - CI (tuple): Confidence interval for the mean difference\n",
    "    \"\"\"\n",
    "\n",
    "    r = np.array(r)\n",
    "    r_hat = np.mean(r)\n",
    "    s_hat = np.std(r, ddof=1)\n",
    "    J = len(r)\n",
    "\n",
    "    # Adjusted standard deviation accounting for correlation\n",
    "    sigma_tilde = s_hat * np.sqrt((1 / J) + (rho / (1 - rho)))\n",
    "\n",
    "    # Confidence interval\n",
    "    CI = st.t.interval(1 - alpha, df=J - 1, loc=r_hat, scale=sigma_tilde)\n",
    "\n",
    "    # Two-sided p-value\n",
    "    p = 2 * st.t.cdf(-np.abs(r_hat) / sigma_tilde, df=J - 1)\n",
    "\n",
    "    return r_hat, CI, p\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "   \n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "\n",
    "    y_train_mean = y_train.mean()\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    y_train = y_train - y_train_mean\n",
    "    y_val   = y_val   - y_train_mean\n",
    "\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf06ee4",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10 # Repetitions\n",
    "K = 10 # Folds\n",
    "rho = 1 / K # Correlation heuristic\n",
    "alpha = 0.05 # Significance level\n",
    "\n",
    "# ANN parameters\n",
    "\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0.9\n",
    "\n",
    "#Loss Function \n",
    "l2_loss = lambda y, y_pred: (y - y_pred)**2\n",
    "loss_func = l2_loss # Loss function\n",
    "\n",
    "# Parameters used\n",
    "\n",
    "best_lambda_statistic_test = best_lambda\n",
    "best_hyperparameter_statistic_test = best_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c9370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.73918221350996\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(best_lambda_statistic_test)\n",
    "print(best_hyperparameter_statistic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d4075",
   "metadata": {},
   "source": [
    "### ANN vs Linear Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eefc8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -1923.9072\n",
      "95% CI: [-2940.7422, -907.0723]\n",
      "p-value: 0.00029348441260063687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = Ridge(alpha = best_lambda_statistic_test, random_state=repeat_idx)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg).values.flatten()  # Get individual squared errors as a 1D array\n",
    "\n",
    "        ##################################################### ANN MODEL #################################################\n",
    "\n",
    "        model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "        # Define loss criterion - set reduction to 'none' to get individual errors\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Make a forward pass through the model to compute the outputs\n",
    "            outputs = model(X_train_tensor)\n",
    "            # Compute the loss (this will still be a tensor of individual losses, so take mean for backward)\n",
    "            loss = criterion(outputs, y_train_tensor).mean()  # mean needed for backward\n",
    "\n",
    "            # Make sure that the gradients are zero before you use backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "            loss.backward()\n",
    "            # Update the model parameters by making the optimizer take a gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_losses = criterion(val_outputs, y_test_tensor)  # Tensor of individual squared errors\n",
    "            loss_func_ANN = val_losses.detach().cpu().numpy().flatten()  # Convert to numpy array for all individual errors\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "\n",
    "        r_j = np.mean(loss_func_linear_reg - loss_func_ANN)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a30d7",
   "metadata": {},
   "source": [
    "### ANN vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdef24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:02<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -1377.2755\n",
      "95% CI: [-2502.2910, -252.2600]\n",
      "p-value: 0.016937890092791296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline).values.flatten()\n",
    "\n",
    "        ##################################################### ANN MODEL #################################################\n",
    "\n",
    "        model = get_model(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "        # Define loss criterion - set reduction to 'none' to get individual errors\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        # Define the optimizer as the Adam optimizer (not needed to know the details)\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # Set the model to training mode\n",
    "            model.train()\n",
    "\n",
    "            # Make a forward pass through the model to compute the outputs\n",
    "            outputs = model(X_train_tensor)\n",
    "            # Compute the loss (this will still be a tensor of individual losses, so take mean for backward)\n",
    "            loss = criterion(outputs, y_train_tensor).mean()  # mean needed for backward\n",
    "\n",
    "            # Make sure that the gradients are zero before you use backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            # Do a backward pass to compute the gradients wrt. model parameters using backpropagation.\n",
    "            loss.backward()\n",
    "            # Update the model parameters by making the optimizer take a gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_losses = criterion(val_outputs, y_test_tensor)  # Tensor of individual squared errors\n",
    "            loss_func_ANN = val_losses.detach().cpu().numpy().flatten()  # Convert to numpy array for all individual errors\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "\n",
    "        r_j = np.mean(loss_funcion_baseline - loss_func_ANN)\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f77d6",
   "metadata": {},
   "source": [
    "### Linear Reg vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65bcdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 390.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 437.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 466.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 456.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 460.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 455.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 466.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 457.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 462.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation fold: 100%|██████████| 10/10 [00:00<00:00, 451.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup II results:\n",
      "r_hat: -346.5908\n",
      "95% CI: [-665.1416, -28.0399]\n",
      "p-value: 0.03327646979684049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = Ridge(alpha = best_lambda_statistic_test, random_state=repeat_idx)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline)\n",
    "\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "        \n",
    "        r_j = np.mean(loss_func_linear_reg - loss_funcion_baseline)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c0fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
