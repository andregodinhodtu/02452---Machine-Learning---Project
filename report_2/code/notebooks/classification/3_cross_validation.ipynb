{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8caeade0",
   "metadata": {},
   "source": [
    "# 3_cross_validation_on_classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ba25",
   "metadata": {},
   "source": [
    "## Data import and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13ac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d4a57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data_file=\"heart_failure_clinical_records_dataset\"\n",
    "\n",
    "data = pd.read_csv(f\"../../raw_data/{name_data_file}.csv\", na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d49120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 299 samples, 12 features\n"
     ]
    }
   ],
   "source": [
    "# Split the data frame into features and labels\n",
    "X = data.drop(columns=[\"DEATH_EVENT\"])\n",
    "y = data[\"DEATH_EVENT\"]\n",
    "\n",
    "N, M = X.shape\n",
    "print(f\"Data loaded: {N} samples, {M} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b0a53",
   "metadata": {},
   "source": [
    "# Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb3b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_data(X, y, train_idx, val_idx):\n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val   = X.iloc[val_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_val   = y.iloc[val_idx]\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "\n",
    "def get_fold_data_normalized(X, y, train_idx, val_idx):\n",
    "    X_train, X_val, y_train, y_val = get_fold_data(X, y, train_idx, val_idx)\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std  = X_train.std(axis=0)\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    return X_train_norm, X_val_norm, y_train, y_val\n",
    "\n",
    "\n",
    "def torch_tensor_conversion(X_train, y_train, X_val, y_val):\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor   = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor   = torch.tensor(y_val.values.reshape(-1, 1), dtype=torch.float32).view(-1, 1)\n",
    "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeed493",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a391ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_folds_k_1 = 10\n",
    "inner_folds_k_2 = 10\n",
    "random_state = 42\n",
    "\n",
    "# Hyperparameters to test\n",
    "hyperparameters_tree = [2, 3, 4, 5, 6, 7]       # e.g. max_depth values\n",
    "lambdas_logistic = np.logspace(-4, 3, 7) # e.g. inverse of regularization strength C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8257e2",
   "metadata": {},
   "source": [
    "# Cross_Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aa11d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OUTER FOLD 1\n",
      "Outer Fold 1 - Inner Fold 1\n",
      "Outer Fold 1 - Inner Fold 2\n",
      "Outer Fold 1 - Inner Fold 3\n",
      "Outer Fold 1 - Inner Fold 4\n",
      "Outer Fold 1 - Inner Fold 5\n",
      "Outer Fold 1 - Inner Fold 6\n",
      "Outer Fold 1 - Inner Fold 7\n",
      "Outer Fold 1 - Inner Fold 8\n",
      "Outer Fold 1 - Inner Fold 9\n",
      "Outer Fold 1 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.7667 | Error: 0.2333\n",
      "  ▶ Best Tree Depth: 5\n",
      "Finished Outer Fold 1\n",
      "  OUTER FOLD 2\n",
      "Outer Fold 2 - Inner Fold 1\n",
      "Outer Fold 2 - Inner Fold 2\n",
      "Outer Fold 2 - Inner Fold 3\n",
      "Outer Fold 2 - Inner Fold 4\n",
      "Outer Fold 2 - Inner Fold 5\n",
      "Outer Fold 2 - Inner Fold 6\n",
      "Outer Fold 2 - Inner Fold 7\n",
      "Outer Fold 2 - Inner Fold 8\n",
      "Outer Fold 2 - Inner Fold 9\n",
      "Outer Fold 2 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.8667 | Error: 0.1333\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 2\n",
      "  OUTER FOLD 3\n",
      "Outer Fold 3 - Inner Fold 1\n",
      "Outer Fold 3 - Inner Fold 2\n",
      "Outer Fold 3 - Inner Fold 3\n",
      "Outer Fold 3 - Inner Fold 4\n",
      "Outer Fold 3 - Inner Fold 5\n",
      "Outer Fold 3 - Inner Fold 6\n",
      "Outer Fold 3 - Inner Fold 7\n",
      "Outer Fold 3 - Inner Fold 8\n",
      "Outer Fold 3 - Inner Fold 9\n",
      "Outer Fold 3 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.7667 | Error: 0.2333\n",
      "  ▶ Best Tree Depth: 3\n",
      "Finished Outer Fold 3\n",
      "  OUTER FOLD 4\n",
      "Outer Fold 4 - Inner Fold 1\n",
      "Outer Fold 4 - Inner Fold 2\n",
      "Outer Fold 4 - Inner Fold 3\n",
      "Outer Fold 4 - Inner Fold 4\n",
      "Outer Fold 4 - Inner Fold 5\n",
      "Outer Fold 4 - Inner Fold 6\n",
      "Outer Fold 4 - Inner Fold 7\n",
      "Outer Fold 4 - Inner Fold 8\n",
      "Outer Fold 4 - Inner Fold 9\n",
      "Outer Fold 4 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.9333 | Error: 0.0667\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 4\n",
      "  OUTER FOLD 5\n",
      "Outer Fold 5 - Inner Fold 1\n",
      "Outer Fold 5 - Inner Fold 2\n",
      "Outer Fold 5 - Inner Fold 3\n",
      "Outer Fold 5 - Inner Fold 4\n",
      "Outer Fold 5 - Inner Fold 5\n",
      "Outer Fold 5 - Inner Fold 6\n",
      "Outer Fold 5 - Inner Fold 7\n",
      "Outer Fold 5 - Inner Fold 8\n",
      "Outer Fold 5 - Inner Fold 9\n",
      "Outer Fold 5 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.9000 | Error: 0.1000\n",
      "  ▶ Best Tree Depth: 5\n",
      "Finished Outer Fold 5\n",
      "  OUTER FOLD 6\n",
      "Outer Fold 6 - Inner Fold 1\n",
      "Outer Fold 6 - Inner Fold 2\n",
      "Outer Fold 6 - Inner Fold 3\n",
      "Outer Fold 6 - Inner Fold 4\n",
      "Outer Fold 6 - Inner Fold 5\n",
      "Outer Fold 6 - Inner Fold 6\n",
      "Outer Fold 6 - Inner Fold 7\n",
      "Outer Fold 6 - Inner Fold 8\n",
      "Outer Fold 6 - Inner Fold 9\n",
      "Outer Fold 6 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.8000 | Error: 0.2000\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 6\n",
      "  OUTER FOLD 7\n",
      "Outer Fold 7 - Inner Fold 1\n",
      "Outer Fold 7 - Inner Fold 2\n",
      "Outer Fold 7 - Inner Fold 3\n",
      "Outer Fold 7 - Inner Fold 4\n",
      "Outer Fold 7 - Inner Fold 5\n",
      "Outer Fold 7 - Inner Fold 6\n",
      "Outer Fold 7 - Inner Fold 7\n",
      "Outer Fold 7 - Inner Fold 8\n",
      "Outer Fold 7 - Inner Fold 9\n",
      "Outer Fold 7 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.9333 | Error: 0.0667\n",
      "  ▶ Best Tree Depth: 4\n",
      "Finished Outer Fold 7\n",
      "  OUTER FOLD 8\n",
      "Outer Fold 8 - Inner Fold 1\n",
      "Outer Fold 8 - Inner Fold 2\n",
      "Outer Fold 8 - Inner Fold 3\n",
      "Outer Fold 8 - Inner Fold 4\n",
      "Outer Fold 8 - Inner Fold 5\n",
      "Outer Fold 8 - Inner Fold 6\n",
      "Outer Fold 8 - Inner Fold 7\n",
      "Outer Fold 8 - Inner Fold 8\n",
      "Outer Fold 8 - Inner Fold 9\n",
      "Outer Fold 8 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.8667 | Error: 0.1333\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 8\n",
      "  OUTER FOLD 9\n",
      "Outer Fold 9 - Inner Fold 1\n",
      "Outer Fold 9 - Inner Fold 2\n",
      "Outer Fold 9 - Inner Fold 3\n",
      "Outer Fold 9 - Inner Fold 4\n",
      "Outer Fold 9 - Inner Fold 5\n",
      "Outer Fold 9 - Inner Fold 6\n",
      "Outer Fold 9 - Inner Fold 7\n",
      "Outer Fold 9 - Inner Fold 8\n",
      "Outer Fold 9 - Inner Fold 9\n",
      "Outer Fold 9 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.7667 | Error: 0.2333\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 9\n",
      "  OUTER FOLD 10\n",
      "Outer Fold 10 - Inner Fold 1\n",
      "Outer Fold 10 - Inner Fold 2\n",
      "Outer Fold 10 - Inner Fold 3\n",
      "Outer Fold 10 - Inner Fold 4\n",
      "Outer Fold 10 - Inner Fold 5\n",
      "Outer Fold 10 - Inner Fold 6\n",
      "Outer Fold 10 - Inner Fold 7\n",
      "Outer Fold 10 - Inner Fold 8\n",
      "Outer Fold 10 - Inner Fold 9\n",
      "Outer Fold 10 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.7586 | Error: 0.2414\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 10\n",
      " Nested CV Completed \n",
      "Best Logistic Regression λ per fold:\n",
      "{1: np.float64(4.641588833612782), 2: np.float64(4.641588833612782), 3: np.float64(4.641588833612782), 4: np.float64(0.0001), 5: np.float64(0.0001), 6: np.float64(4.641588833612782), 7: np.float64(4.641588833612782), 8: np.float64(0.0001), 9: np.float64(0.0001), 10: np.float64(0.0001)}\n",
      "Best Tree Depth per fold:\n",
      "{1: 5, 2: 2, 3: 3, 4: 2, 5: 5, 6: 2, 7: 4, 8: 2, 9: 2, 10: 2}\n",
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "    baseline_mean_inner_acc  baseline_outer_acc  baseline_outer_error  \\\n",
      "1                  0.680342            0.666667              0.333333   \n",
      "2                  0.680342            0.666667              0.333333   \n",
      "3                  0.680342            0.666667              0.333333   \n",
      "4                  0.680342            0.666667              0.333333   \n",
      "5                  0.680342            0.666667              0.333333   \n",
      "6                  0.680342            0.666667              0.333333   \n",
      "7                  0.676638            0.700000              0.300000   \n",
      "8                  0.676638            0.700000              0.300000   \n",
      "9                  0.676638            0.700000              0.300000   \n",
      "10                 0.677778            0.689655              0.310345   \n",
      "\n",
      "    logistic_best_lambda  logistic_outer_acc  logistic_outer_error  \\\n",
      "1               4.641589            0.766667              0.233333   \n",
      "2               4.641589            0.866667              0.133333   \n",
      "3               4.641589            0.766667              0.233333   \n",
      "4               0.000100            0.933333              0.066667   \n",
      "5               0.000100            0.900000              0.100000   \n",
      "6               4.641589            0.800000              0.200000   \n",
      "7               4.641589            0.933333              0.066667   \n",
      "8               0.000100            0.866667              0.133333   \n",
      "9               0.000100            0.766667              0.233333   \n",
      "10              0.000100            0.758621              0.241379   \n",
      "\n",
      "    tree_best_depth  tree_outer_acc  tree_outer_error  \n",
      "1                 5        0.700000          0.300000  \n",
      "2                 2        0.966667          0.033333  \n",
      "3                 3        0.800000          0.200000  \n",
      "4                 2        0.800000          0.200000  \n",
      "5                 5        0.800000          0.200000  \n",
      "6                 2        0.766667          0.233333  \n",
      "7                 4        0.833333          0.166667  \n",
      "8                 2        0.800000          0.200000  \n",
      "9                 2        0.833333          0.166667  \n",
      "10                2        0.827586          0.172414  \n"
     ]
    }
   ],
   "source": [
    "# Outer CV\n",
    "CV_outer = StratifiedKFold(n_splits=outer_folds_k_1, shuffle=True, random_state=random_state)\n",
    "\n",
    "fold_results = {}\n",
    "best_hyperparameters_logistic = {}\n",
    "best_hyperparameters_tree = {}\n",
    "outer_fold_index = 0\n",
    "\n",
    "for outer_train_idx, outer_test_idx in CV_outer.split(X, y):\n",
    "    outer_fold_index += 1\n",
    "    print(f\"  OUTER FOLD {outer_fold_index}\")\n",
    "\n",
    "    X_train_outer, X_test_outer = X.iloc[outer_train_idx].copy(), X.iloc[outer_test_idx].copy()\n",
    "    y_train_outer, y_test_outer = y.iloc[outer_train_idx].copy(), y.iloc[outer_test_idx].copy()\n",
    "\n",
    "    mu_X_train = X_train_outer.mean(axis=0)\n",
    "    sigma_X_train = X_train_outer.std(axis=0, ddof=0)\n",
    "    X_train_outer_scaled = (X_train_outer - mu_X_train) / sigma_X_train\n",
    "    X_test_outer_scaled  = (X_test_outer  - mu_X_train) / sigma_X_train\n",
    "\n",
    "    CV_inner = StratifiedKFold(n_splits=inner_folds_k_2, shuffle=True, random_state=outer_fold_index)\n",
    "    inner_acc_baseline = {}\n",
    "    inner_acc_logistic = {}\n",
    "    inner_acc_tree = {}\n",
    "    inner_fold_index = 0\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in CV_inner.split(X_train_outer_scaled, y_train_outer):\n",
    "        inner_fold_index += 1\n",
    "        print(f\"Outer Fold {outer_fold_index} - Inner Fold {inner_fold_index}\")\n",
    "\n",
    "        X_train_inner = X_train_outer_scaled.iloc[inner_train_idx]\n",
    "        X_val_inner   = X_train_outer_scaled.iloc[inner_test_idx]\n",
    "        y_train_inner = y_train_outer.iloc[inner_train_idx]\n",
    "        y_val_inner   = y_train_outer.iloc[inner_test_idx]\n",
    "\n",
    "        ############################# BASELINE Inner Fold ####################################\n",
    "        majority_class = y_train_inner.mode()[0]\n",
    "        y_val_pred = np.full_like(y_val_inner, fill_value=majority_class)\n",
    "        acc = accuracy_score(y_val_inner, y_val_pred)\n",
    "        inner_acc_baseline[inner_fold_index] = acc\n",
    "\n",
    "        ############################# LOGISTIC REGRESSION Inner Fold ####################################\n",
    "        results_inner_logistic = {lam: {'val_error': []} for lam in lambdas_logistic}\n",
    "\n",
    "        for lam in lambdas_logistic:\n",
    "            model = LogisticRegression(penalty=\"l2\", C=1/lam, solver=\"lbfgs\", max_iter=1000, random_state=random_state)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val_inner)\n",
    "            val_error = zero_one_loss(y_val_inner, y_val_pred)\n",
    "            results_inner_logistic[lam]['val_error'].append(val_error)\n",
    "\n",
    "        inner_acc_logistic[inner_fold_index] = results_inner_logistic\n",
    "\n",
    "        ############################# DECISION TREE Inner Fold ####################################\n",
    "        results_inner_tree = {depth: {'val_error': []} for depth in hyperparameters_tree}\n",
    "\n",
    "        for depth in hyperparameters_tree:\n",
    "            tree = DecisionTreeClassifier(max_depth=depth, criterion='log_loss', random_state=random_state)\n",
    "            tree.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = tree.predict(X_val_inner)\n",
    "            val_error = zero_one_loss(y_val_inner, y_val_pred)\n",
    "            results_inner_tree[depth]['val_error'].append(val_error)\n",
    "\n",
    "        inner_acc_tree[inner_fold_index] = results_inner_tree\n",
    "\n",
    "    ############################# LOGISTIC REGRESSION Outer Fold ####################################\n",
    "    avg_val_error_per_lambda = {}\n",
    "    for lam in lambdas_logistic:\n",
    "        val_errors = []\n",
    "        for inner_fold in inner_acc_logistic.keys():\n",
    "            val_errors.extend(inner_acc_logistic[inner_fold][lam]['val_error'])\n",
    "        avg_val_error_per_lambda[lam] = np.mean(val_errors)\n",
    "\n",
    "    best_lambda = min(avg_val_error_per_lambda, key=avg_val_error_per_lambda.get)\n",
    "    best_hyperparameters_logistic[outer_fold_index] = best_lambda\n",
    "    print(f\"  ▶ Best λ (regularization): {best_lambda:.5f}\")\n",
    "\n",
    "    final_model = LogisticRegression(penalty=\"l2\", C=1/best_lambda, solver=\"lbfgs\",\n",
    "                                     max_iter=1000, random_state=random_state)\n",
    "    final_model.fit(X_train_outer_scaled, y_train_outer)\n",
    "    y_test_pred = final_model.predict(X_test_outer_scaled)\n",
    "    outer_test_error = zero_one_loss(y_test_outer, y_test_pred)\n",
    "    outer_test_acc = accuracy_score(y_test_outer, y_test_pred)\n",
    "\n",
    "    print(f\"  Logistic Regression Outer Test Accuracy: {outer_test_acc:.4f} | Error: {outer_test_error:.4f}\")\n",
    "\n",
    "    ############################# BASELINE Outer Fold ####################################\n",
    "    mean_acc_inner_baseline = np.mean(list(inner_acc_baseline.values()))\n",
    "    majority_class_outer = y_train_outer.mode()[0]\n",
    "    y_pred_baseline_outer = np.full_like(y_test_outer, fill_value=majority_class_outer)\n",
    "    baseline_acc_outer = accuracy_score(y_test_outer, y_pred_baseline_outer)\n",
    "    baseline_error_outer = zero_one_loss(y_test_outer, y_pred_baseline_outer)\n",
    "\n",
    "    ############################# DECISION TREE Outer Fold ####################################\n",
    "    avg_val_error_per_depth = {\n",
    "        depth: np.mean([err\n",
    "                        for fold in inner_acc_tree.keys()\n",
    "                        for err in inner_acc_tree[fold][depth]['val_error']])\n",
    "        for depth in hyperparameters_tree\n",
    "    }\n",
    "    best_depth = min(avg_val_error_per_depth, key=avg_val_error_per_depth.get)\n",
    "    best_hyperparameters_tree[outer_fold_index] = best_depth\n",
    "    print(f\"  ▶ Best Tree Depth: {best_depth}\")\n",
    "\n",
    "    final_tree = DecisionTreeClassifier(max_depth=best_depth, criterion='log_loss', random_state=random_state)\n",
    "    final_tree.fit(X_train_outer_scaled, y_train_outer)\n",
    "    y_test_pred_tree = final_tree.predict(X_test_outer_scaled)\n",
    "    outer_test_error_tree = zero_one_loss(y_test_outer, y_test_pred_tree)\n",
    "    outer_test_acc_tree = accuracy_score(y_test_outer, y_test_pred_tree)\n",
    "\n",
    "    ############################# STORE RESULTS ####################################\n",
    "    fold_results[outer_fold_index] = {\n",
    "        \"baseline_mean_inner_acc\": mean_acc_inner_baseline,\n",
    "        \"baseline_outer_acc\": baseline_acc_outer,\n",
    "        \"baseline_outer_error\": baseline_error_outer,\n",
    "        \"logistic_best_lambda\": best_lambda,\n",
    "        \"logistic_outer_acc\": outer_test_acc,\n",
    "        \"logistic_outer_error\": outer_test_error,\n",
    "        \"tree_best_depth\": best_depth,\n",
    "        \"tree_outer_acc\": outer_test_acc_tree,\n",
    "        \"tree_outer_error\": outer_test_error_tree\n",
    "    }\n",
    "\n",
    "    print(f\"Finished Outer Fold {outer_fold_index}\")\n",
    "\n",
    "print(\" Nested CV Completed \")\n",
    "print(\"Best Logistic Regression λ per fold:\")\n",
    "print(best_hyperparameters_logistic)\n",
    "print(\"Best Tree Depth per fold:\")\n",
    "print(best_hyperparameters_tree)\n",
    "\n",
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(outer_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OUTER FOLD 1\n",
      "Outer Fold 1 - Inner Fold 1\n",
      "Outer Fold 1 - Inner Fold 2\n",
      "Outer Fold 1 - Inner Fold 3\n",
      "Outer Fold 1 - Inner Fold 4\n",
      "Outer Fold 1 - Inner Fold 5\n",
      "Outer Fold 1 - Inner Fold 6\n",
      "Outer Fold 1 - Inner Fold 7\n",
      "Outer Fold 1 - Inner Fold 8\n",
      "Outer Fold 1 - Inner Fold 9\n",
      "Outer Fold 1 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.7667 | Error: 0.2333\n",
      "  ▶ Best Tree Depth: 5\n",
      "Finished Outer Fold 1\n",
      "  OUTER FOLD 2\n",
      "Outer Fold 2 - Inner Fold 1\n",
      "Outer Fold 2 - Inner Fold 2\n",
      "Outer Fold 2 - Inner Fold 3\n",
      "Outer Fold 2 - Inner Fold 4\n",
      "Outer Fold 2 - Inner Fold 5\n",
      "Outer Fold 2 - Inner Fold 6\n",
      "Outer Fold 2 - Inner Fold 7\n",
      "Outer Fold 2 - Inner Fold 8\n",
      "Outer Fold 2 - Inner Fold 9\n",
      "Outer Fold 2 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.8667 | Error: 0.1333\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 2\n",
      "  OUTER FOLD 3\n",
      "Outer Fold 3 - Inner Fold 1\n",
      "Outer Fold 3 - Inner Fold 2\n",
      "Outer Fold 3 - Inner Fold 3\n",
      "Outer Fold 3 - Inner Fold 4\n",
      "Outer Fold 3 - Inner Fold 5\n",
      "Outer Fold 3 - Inner Fold 6\n",
      "Outer Fold 3 - Inner Fold 7\n",
      "Outer Fold 3 - Inner Fold 8\n",
      "Outer Fold 3 - Inner Fold 9\n",
      "Outer Fold 3 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.7667 | Error: 0.2333\n",
      "  ▶ Best Tree Depth: 3\n",
      "Finished Outer Fold 3\n",
      "  OUTER FOLD 4\n",
      "Outer Fold 4 - Inner Fold 1\n",
      "Outer Fold 4 - Inner Fold 2\n",
      "Outer Fold 4 - Inner Fold 3\n",
      "Outer Fold 4 - Inner Fold 4\n",
      "Outer Fold 4 - Inner Fold 5\n",
      "Outer Fold 4 - Inner Fold 6\n",
      "Outer Fold 4 - Inner Fold 7\n",
      "Outer Fold 4 - Inner Fold 8\n",
      "Outer Fold 4 - Inner Fold 9\n",
      "Outer Fold 4 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.9333 | Error: 0.0667\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 4\n",
      "  OUTER FOLD 5\n",
      "Outer Fold 5 - Inner Fold 1\n",
      "Outer Fold 5 - Inner Fold 2\n",
      "Outer Fold 5 - Inner Fold 3\n",
      "Outer Fold 5 - Inner Fold 4\n",
      "Outer Fold 5 - Inner Fold 5\n",
      "Outer Fold 5 - Inner Fold 6\n",
      "Outer Fold 5 - Inner Fold 7\n",
      "Outer Fold 5 - Inner Fold 8\n",
      "Outer Fold 5 - Inner Fold 9\n",
      "Outer Fold 5 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.9000 | Error: 0.1000\n",
      "  ▶ Best Tree Depth: 5\n",
      "Finished Outer Fold 5\n",
      "  OUTER FOLD 6\n",
      "Outer Fold 6 - Inner Fold 1\n",
      "Outer Fold 6 - Inner Fold 2\n",
      "Outer Fold 6 - Inner Fold 3\n",
      "Outer Fold 6 - Inner Fold 4\n",
      "Outer Fold 6 - Inner Fold 5\n",
      "Outer Fold 6 - Inner Fold 6\n",
      "Outer Fold 6 - Inner Fold 7\n",
      "Outer Fold 6 - Inner Fold 8\n",
      "Outer Fold 6 - Inner Fold 9\n",
      "Outer Fold 6 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.8000 | Error: 0.2000\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 6\n",
      "  OUTER FOLD 7\n",
      "Outer Fold 7 - Inner Fold 1\n",
      "Outer Fold 7 - Inner Fold 2\n",
      "Outer Fold 7 - Inner Fold 3\n",
      "Outer Fold 7 - Inner Fold 4\n",
      "Outer Fold 7 - Inner Fold 5\n",
      "Outer Fold 7 - Inner Fold 6\n",
      "Outer Fold 7 - Inner Fold 7\n",
      "Outer Fold 7 - Inner Fold 8\n",
      "Outer Fold 7 - Inner Fold 9\n",
      "Outer Fold 7 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 4.64159\n",
      "  Logistic Regression Outer Test Accuracy: 0.9333 | Error: 0.0667\n",
      "  ▶ Best Tree Depth: 4\n",
      "Finished Outer Fold 7\n",
      "  OUTER FOLD 8\n",
      "Outer Fold 8 - Inner Fold 1\n",
      "Outer Fold 8 - Inner Fold 2\n",
      "Outer Fold 8 - Inner Fold 3\n",
      "Outer Fold 8 - Inner Fold 4\n",
      "Outer Fold 8 - Inner Fold 5\n",
      "Outer Fold 8 - Inner Fold 6\n",
      "Outer Fold 8 - Inner Fold 7\n",
      "Outer Fold 8 - Inner Fold 8\n",
      "Outer Fold 8 - Inner Fold 9\n",
      "Outer Fold 8 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.8667 | Error: 0.1333\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 8\n",
      "  OUTER FOLD 9\n",
      "Outer Fold 9 - Inner Fold 1\n",
      "Outer Fold 9 - Inner Fold 2\n",
      "Outer Fold 9 - Inner Fold 3\n",
      "Outer Fold 9 - Inner Fold 4\n",
      "Outer Fold 9 - Inner Fold 5\n",
      "Outer Fold 9 - Inner Fold 6\n",
      "Outer Fold 9 - Inner Fold 7\n",
      "Outer Fold 9 - Inner Fold 8\n",
      "Outer Fold 9 - Inner Fold 9\n",
      "Outer Fold 9 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.7667 | Error: 0.2333\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 9\n",
      "  OUTER FOLD 10\n",
      "Outer Fold 10 - Inner Fold 1\n",
      "Outer Fold 10 - Inner Fold 2\n",
      "Outer Fold 10 - Inner Fold 3\n",
      "Outer Fold 10 - Inner Fold 4\n",
      "Outer Fold 10 - Inner Fold 5\n",
      "Outer Fold 10 - Inner Fold 6\n",
      "Outer Fold 10 - Inner Fold 7\n",
      "Outer Fold 10 - Inner Fold 8\n",
      "Outer Fold 10 - Inner Fold 9\n",
      "Outer Fold 10 - Inner Fold 10\n",
      "  ▶ Best λ (regularization): 0.00010\n",
      "  Logistic Regression Outer Test Accuracy: 0.7586 | Error: 0.2414\n",
      "  ▶ Best Tree Depth: 2\n",
      "Finished Outer Fold 10\n",
      "Nested CV Completed\n",
      "Best Logistic Regression λ per fold:\n",
      "{1: np.float64(4.641588833612782), 2: np.float64(4.641588833612782), 3: np.float64(4.641588833612782), 4: np.float64(0.0001), 5: np.float64(0.0001), 6: np.float64(4.641588833612782), 7: np.float64(4.641588833612782), 8: np.float64(0.0001), 9: np.float64(0.0001), 10: np.float64(0.0001)}\n",
      "Best Tree Depth per fold:\n",
      "{1: 5, 2: 2, 3: 3, 4: 2, 5: 5, 6: 2, 7: 4, 8: 2, 9: 2, 10: 2}\n",
      "\n",
      "=== Summary of Outer Fold Results ===\n",
      "    baseline_outer_acc  baseline_outer_error  logistic_best_lambda  \\\n",
      "1             0.666667              0.333333              4.641589   \n",
      "2             0.666667              0.333333              4.641589   \n",
      "3             0.666667              0.333333              4.641589   \n",
      "4             0.666667              0.333333              0.000100   \n",
      "5             0.666667              0.333333              0.000100   \n",
      "6             0.666667              0.333333              4.641589   \n",
      "7             0.700000              0.300000              4.641589   \n",
      "8             0.700000              0.300000              0.000100   \n",
      "9             0.700000              0.300000              0.000100   \n",
      "10            0.689655              0.310345              0.000100   \n",
      "\n",
      "    logistic_outer_acc  logistic_outer_error  tree_best_depth  tree_outer_acc  \\\n",
      "1             0.766667              0.233333                5        0.766667   \n",
      "2             0.866667              0.133333                2        0.966667   \n",
      "3             0.766667              0.233333                3        0.800000   \n",
      "4             0.933333              0.066667                2        0.800000   \n",
      "5             0.900000              0.100000                5        0.800000   \n",
      "6             0.800000              0.200000                2        0.766667   \n",
      "7             0.933333              0.066667                4        0.833333   \n",
      "8             0.866667              0.133333                2        0.800000   \n",
      "9             0.766667              0.233333                2        0.833333   \n",
      "10            0.758621              0.241379                2        0.827586   \n",
      "\n",
      "    tree_outer_error  \n",
      "1           0.233333  \n",
      "2           0.033333  \n",
      "3           0.200000  \n",
      "4           0.200000  \n",
      "5           0.200000  \n",
      "6           0.233333  \n",
      "7           0.166667  \n",
      "8           0.200000  \n",
      "9           0.166667  \n",
      "10          0.172414  \n"
     ]
    }
   ],
   "source": [
    "CV_outer = StratifiedKFold(n_splits=outer_folds_k_1, shuffle=True, random_state=random_state)\n",
    "\n",
    "fold_results = {}\n",
    "best_hyperparameters_logistic = {}\n",
    "best_hyperparameters_tree = {}\n",
    "outer_fold_index = 0\n",
    "\n",
    "for outer_train_idx, outer_test_idx in CV_outer.split(X, y):\n",
    "    outer_fold_index += 1\n",
    "    print(f\"  OUTER FOLD {outer_fold_index}\")\n",
    "\n",
    "    ############################ DATA Outer Fold ####################################\n",
    "\n",
    "    X_train_outer, X_test_outer, y_train_outer, y_test_outer = get_fold_data(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    CV_inner = StratifiedKFold(n_splits=inner_folds_k_2, shuffle=True, random_state=outer_fold_index)\n",
    "    inner_acc_baseline = {}\n",
    "    inner_acc_logistic = {}\n",
    "    inner_acc_tree = {}\n",
    "    inner_fold_index = 0\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in CV_inner.split(X_train_outer, y_train_outer):\n",
    "        inner_fold_index += 1\n",
    "        print(f\"Outer Fold {outer_fold_index} - Inner Fold {inner_fold_index}\")\n",
    "\n",
    "        ############################ DATA Inner Fold ####################################\n",
    "\n",
    "        X_train_inner_norm, X_test_inner_norm, y_train_inner_norm, y_test_inner_norm = get_fold_data_normalized(X_train_outer, y_train_outer, inner_train_idx, inner_test_idx)\n",
    "\n",
    "        ############################# LOGISTIC REGRESSION Inner Fold ####################################\n",
    "        results_inner_logistic = {lam: {'val_error': []} for lam in lambdas_logistic}\n",
    "\n",
    "        for lam in lambdas_logistic:\n",
    "            model = LogisticRegression(penalty=\"l2\", C=1/lam, solver=\"lbfgs\", max_iter=1000, random_state=random_state)\n",
    "            model.fit(X_train_inner_norm, y_train_inner_norm)\n",
    "            y_val_pred = model.predict(X_test_inner_norm)\n",
    "            val_error = zero_one_loss(y_test_inner_norm, y_val_pred)\n",
    "            results_inner_logistic[lam]['val_error'].append(val_error)\n",
    "\n",
    "        inner_acc_logistic[inner_fold_index] = results_inner_logistic\n",
    "\n",
    "        ############################# DECISION TREE Inner Fold ####################################\n",
    "\n",
    "        results_inner_tree = {depth: {'val_error': []} for depth in hyperparameters_tree}\n",
    "\n",
    "        for depth in hyperparameters_tree:\n",
    "            tree = DecisionTreeClassifier(max_depth=depth, criterion='log_loss', random_state=random_state)\n",
    "            tree.fit(X_train_inner_norm, y_train_inner_norm)\n",
    "            y_val_pred = tree.predict(X_test_inner_norm)\n",
    "            val_error = zero_one_loss(y_test_inner_norm, y_val_pred)\n",
    "            results_inner_tree[depth]['val_error'].append(val_error)\n",
    "\n",
    "        inner_acc_tree[inner_fold_index] = results_inner_tree\n",
    "\n",
    "        ############################# BASELINE Inner Fold (REMOVED) ####################################\n",
    "\n",
    "        # -----\n",
    "\n",
    "        ######################## OUTER FOLD ##########################################################\n",
    "\n",
    "    ############################ Data ####################################\n",
    "\n",
    "    X_train_outer_norm, X_test_outer_norm, y_train_outer_norm, y_test_outer_norm = get_fold_data_normalized(X, y, outer_train_idx, outer_test_idx)\n",
    "\n",
    "    ############################# LOGISTIC REGRESSION Outer Fold ####################################\n",
    "\n",
    "    avg_val_error_per_lambda = {}\n",
    "    for lam in lambdas_logistic:\n",
    "        val_errors = []\n",
    "        for inner_fold in inner_acc_logistic.keys():\n",
    "            val_errors.extend(inner_acc_logistic[inner_fold][lam]['val_error'])\n",
    "        avg_val_error_per_lambda[lam] = np.mean(val_errors)\n",
    "\n",
    "    best_lambda = min(avg_val_error_per_lambda, key=avg_val_error_per_lambda.get)\n",
    "    best_hyperparameters_logistic[outer_fold_index] = best_lambda\n",
    "    print(f\"  ▶ Best λ (regularization): {best_lambda:.5f}\")\n",
    "\n",
    "    final_model = LogisticRegression(\n",
    "        penalty=\"l2\", C=1/best_lambda, solver=\"lbfgs\", max_iter=1000, random_state=random_state\n",
    "    )\n",
    "    final_model.fit(X_train_outer_norm, y_train_outer_norm)\n",
    "    y_test_pred = final_model.predict(X_test_outer_norm)\n",
    "    outer_test_error = zero_one_loss(y_test_outer_norm, y_test_pred)\n",
    "    outer_test_acc = accuracy_score(y_test_outer_norm, y_test_pred)\n",
    "\n",
    "    print(f\"  Logistic Regression Outer Test Accuracy: {outer_test_acc:.4f} | Error: {outer_test_error:.4f}\")\n",
    "\n",
    "    ############################# DECISION TREE Outer Fold ####################################\n",
    "\n",
    "    avg_val_error_per_depth = {\n",
    "        depth: np.mean([\n",
    "            err for fold in inner_acc_tree.keys()\n",
    "            for err in inner_acc_tree[fold][depth]['val_error']\n",
    "        ])\n",
    "        for depth in hyperparameters_tree\n",
    "    }\n",
    "\n",
    "    best_depth = min(avg_val_error_per_depth, key=avg_val_error_per_depth.get)\n",
    "    best_hyperparameters_tree[outer_fold_index] = best_depth\n",
    "    print(f\"  ▶ Best Tree Depth: {best_depth}\")\n",
    "\n",
    "    final_tree = DecisionTreeClassifier(max_depth=best_depth, criterion='log_loss', random_state=random_state)\n",
    "    final_tree.fit(X_train_outer_norm, y_train_outer_norm)\n",
    "    y_test_pred_tree = final_tree.predict(X_test_outer_norm)\n",
    "    outer_test_error_tree = zero_one_loss(y_test_outer_norm, y_test_pred_tree)\n",
    "    outer_test_acc_tree = accuracy_score(y_test_outer_norm, y_test_pred_tree)\n",
    "\n",
    "    ############################# BASELINE Outer Fold ####################################\n",
    "\n",
    "    majority_class_outer = y_train_outer_norm.mode()[0]\n",
    "    y_pred_baseline_outer = np.full_like(y_test_outer_norm, fill_value=majority_class_outer)\n",
    "    baseline_acc_outer = accuracy_score(y_test_outer_norm, y_pred_baseline_outer)\n",
    "    baseline_error_outer = zero_one_loss(y_test_outer_norm, y_pred_baseline_outer)\n",
    "\n",
    "\n",
    "    ############################# STORE RESULTS ####################################\n",
    "    fold_results[outer_fold_index] = {\n",
    "        \"baseline_outer_acc\": baseline_acc_outer,\n",
    "        \"baseline_outer_error\": baseline_error_outer,\n",
    "        \"logistic_best_lambda\": best_lambda,\n",
    "        \"logistic_outer_acc\": outer_test_acc,\n",
    "        \"logistic_outer_error\": outer_test_error,\n",
    "        \"tree_best_depth\": best_depth,\n",
    "        \"tree_outer_acc\": outer_test_acc_tree,\n",
    "        \"tree_outer_error\": outer_test_error_tree\n",
    "    }\n",
    "\n",
    "    print(f\"Finished Outer Fold {outer_fold_index}\")\n",
    "\n",
    "print(\"Nested CV Completed\")\n",
    "print(\"Best Logistic Regression λ per fold:\")\n",
    "print(best_hyperparameters_logistic)\n",
    "print(\"Best Tree Depth per fold:\")\n",
    "print(best_hyperparameters_tree)\n",
    "\n",
    "outer_results_df = pd.DataFrame.from_dict(fold_results, orient='index')\n",
    "print(\"\\n=== Summary of Outer Fold Results ===\")\n",
    "print(outer_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c5691",
   "metadata": {},
   "source": [
    "code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ced5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10 # Repetitions\n",
    "K = 10 # Folds\n",
    "rho = 1 / K # Correlation heuristic\n",
    "alpha = 0.05 # Significance level\n",
    "\n",
    "# ANN parameters\n",
    "\n",
    "input_dim  = M # M number of features\n",
    "output_dim = 1 # regression problem\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "momentum = 0.9\n",
    "\n",
    "#Loss Function \n",
    "l2_loss = lambda y, y_pred: (y - y_pred)**2\n",
    "loss_func = l2_loss # Loss function\n",
    "\n",
    "# Parameters used\n",
    "\n",
    "best_lambda_statistic_test = best_lambda\n",
    "best_hyperparameter_statistic_test = best_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "\n",
    "for repeat_idx in range(m):\n",
    "    print(f\"Repetition {repeat_idx+1}/{m}\")\n",
    "\n",
    "    # 5.2) Initialize KFold cross-validation, set the seed to repeat_idx\n",
    "    ### BEGIN SOLUTION\n",
    "    CV_kfold = KFold(n_splits=K, shuffle=True, random_state=repeat_idx)\n",
    "    ### END SOLUTION\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(CV_kfold.split(X)), total=CV_kfold.get_n_splits(X),desc=\"Cross-validation fold\"):\n",
    "        # Split data into training and test sets\n",
    "\n",
    "        ############################################# DATA #################################################\n",
    "\n",
    "        X_train_norm, X_test_norm, y_train_norm, y_test_norm= get_fold_data_normalized(X, y, train_index, test_index)\n",
    "\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = torch_tensor_conversion(X_train_norm, y_train_norm, X_test_norm, y_test_norm)\n",
    "\n",
    "        ############################################# LINEAR REGRESSION #################################################\n",
    "\n",
    "        model = LogisticRegression(penalty=\"l2\", C=1/lam, solver=\"lbfgs\", max_iter=1000, random_state=random_state)\n",
    "        model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "        y_test_linear_reg = model.predict(X_test_norm)\n",
    "        loss_func_linear_reg = loss_func(y_test_norm, y_test_linear_reg)\n",
    "\n",
    "        ############################################# BASELINE #################################################\n",
    "\n",
    "        y_train_mean_baseline = y_train_norm.mean()\n",
    "        y_test_pred_baseline = pd.Series(y_train_mean_baseline, index=y_test_norm.index)\n",
    "        loss_funcion_baseline = loss_func(y_test_norm, y_test_pred_baseline)\n",
    "\n",
    "\n",
    "        ######################################################### MODELS COMPARISON #######################################\n",
    "        \n",
    "        r_j = np.mean(loss_func_linear_reg - loss_funcion_baseline)\n",
    "\n",
    "        r.append(r_j)\n",
    "\n",
    "# Calculate p-value and confidence interval using correlated t-test\n",
    "r_hat, CI, p_value = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "print(f\"\\nSetup II results:\")\n",
    "print(f\"r_hat: {r_hat:.4f}\")\n",
    "print(f\"95% CI: [{CI[0]:.4f}, {CI[1]:.4f}]\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
